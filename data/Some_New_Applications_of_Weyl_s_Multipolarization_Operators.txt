                                                       Some New Applications of Weyl’s Multi-Polarization Operators

                                                                                  Jacob Towber

                                                       Department of Mathematics, De Paul University, Chicago, Illinois 60614
                                                                        E-mail: jtowber@condor.depaul.edu
arXiv:math/0102156v1 [math.RT] 20 Feb 2001




                                                                             Introduction: Part One

                                                 Let AN denote the enveloping algebra of glN (C).

                                                 In Chapter Two of The Classical Groups,[W], Weyl constructed certain distinguished
                                             elements of AN , which he called quasi-compositions; for a more modern presentation of
                                             this material, see (Fulton and Harris,[FH,pp 514-515].). One of the main purposes of the
                                             present paper, is to direct the attention of representation-theorists to these remarkable
                                             (but rather neglected) objects in AN .
                                                 These objects will here be referred to, equivalently, as “multi-polarizations” or as
                                             “Weyl polarizations”; their definitions will be explained in §1.3 below. Weyl used them for
                                             the purpose of proving the celebrated Capelli identities in AN , which in turn he utilized
                                             to prove what is often called (following Weyl’s nomenclature) the ‘First Fundamental
                                             Theorem of Invariant Theory’ for the classical groups.
                                                 But, in fact, these Weyl polarizations are not necessary, (and are no longer usually
                                             used), for either of these two original purposes. Indeed, Capelli himself did not require
                                             (nor mention) these multi-polarizations, at least not in [Cap1]( the reference cited by Weyl
                                             in [Weyl], p.39), nor in [Cap2] (as cited by Young in [Young], pp.64–71), nor in [Cap3].
                                             (For interesting summaries of Capelli’s work, cf. ([Young,loc.cit.], [Umeda].)
                                                 Let it be emphasized at this point, that the present paper is NOT further concerned,
                                             either with the Capelli identities, or with the First Fundamental Theorem of Invariant
                                             Theory.

                                                 Thus, to make plausible the claim (here proposed) that the Weyl polarizations deserve
                                             further investigation, would seem to require obtaining some newer applications of these
                                             objects, to topics of more current interest, and with results which have not been obtained
                                             by other methods. Two such applications will be presented in the following paper, one
                                             to the Verma-Shapovalov element (mapping one Verma module into another), the other

                                                                                          1
to the remarkable complexes (constructed by A.Zelevinsky in [Zel]), which (together with
their ‘conjugates’, under the interchange of symmetrization and alternation), furnish higher
syzygies, for the Weyl modules defined in [CL], and for the Plücker equations which define
the dual Weyl modules (also called shape functors or Schur functors).
    We postpone until Part Two of the introduction, a sketch of issues involved in the
second of these new applications of the Weyl polarizations.
    Here are the main results concerning the Weyl polarizations, to be established in the
present paper:
    I) Weyl’s original construction of the Weyl polarizations, as differential operators,
is recalled in Def.1.3.1 below. A remarkably simple and quite different-looking, purely
combinatorial construction (which, it is hoped, is new) is given in Def.1.3.2; these two
constructions are proved equivalent in Th.2.3.1. It is this combinatorial construction which
plays a natural role in the study of the syzygies of the Plücker equations, as will be
explained in §3.1, and which make it plausible (it is here proposed) that still further
applications may exist for the Weyl polarizations.
    II) The definition of the Verma-Shapovalov element is reviewed in §3.3 below. The
work of Zelevinsky ([Zel]) and its later development by Akin ([Akin1,2]) relates this element
to the above-mentioned complexes, and hence to the Weyl polarizations. (I should like to
thank Bhama Srinivasan for calling this connection to my attention.) There is obtained
below an explicit formula, stated in §3.3, expressing the action on


                                   SV ⊗ SV ⊗ · · · ⊗ SV
                                   |       {z          }
                                          N times


of the Verma-Shapovalov element for slN (C), as a Z-linear combination of Weyl polariza-
tions. (This appears not to be an obvious consequence of two explicit formulas for the
Verma-Shapovalov element which have appeared in the literature, but which do not utilize
the Weyl polarizations, viz. the formula given by Carter and Lusztig in [CL], and that
given by[MFF].)
    III) Explicit formulas in terms of the Weyl polarizations, which the author believes
are new, are given in §3.1, for the differentials in the Zelevinsky complex discussed in the
following sub-section.
    These formulas are shown in §3.2 to check with earlier precise data for the special case
N = 3, presented by Doty in ([Doty],p.134–136), and there attributed to Verma.

                                             2
     IV) The proofs of the results just cited, utilize formulas (analogous to the Pieri formu-
las) for the product of a Weyl polarization by an elementary polarization.These formulas
are derived in §2.1 and §2.2.

     The present author wishes to acknowledge his debt to D.-N. Verma, for explaining in a
number of public lectures over the past 20 years or so, the problem of explicitly defining the
differentials in the above-mentioned complex; and to acknowledge in addition, a number of
very illuminating conversations with Verma concerning these matters. The author is also
indebted to J.Humphreys and A.Zelevinsky, for helpful suggestions concerning the rather
large literature involving the Shapovalov element.
     Two members of the De Paul University Information Services who were especially
helpful in the preparation of this manuscript were Dan Wanek and Rick Cruz. Thanks are
also due the University of Illinois at Chicago for extending the author its hospitality, as a
Visiting Scholar, during the period this paper was written. Gratitude is especially owed
the UIC library staff for help in obtaining some of the nineteenth-century work of Capelli;
I should especially like to thank D.L.Thomas (Library Associate for the UIC Mathematics
Department), and also Helen Badawi (Public Service Supervisor for the Science Library)
and Gladys Odegaard (Reference Librarian for the Science Library).
     Last (but not least), I wish to acknowledge my wife Diane’s help and encouragement.

                  Introduction: Part Two The Zelevinsky Complex

     The Weyl polarizations seem extremely well-suited, to furnishing explicit formulas for
the differentials in certain remarkable complexes which occur in representation-theory.

     The starting point here is the mid-nineteenth-century Jacobi-Trudi identity between
two symmetric polynomials in x1 , · · · , xm , namely
                                                                                   
                                       ha1           ha1 +1         · · · ha1 +N−1 
                                                                                   
                                          ha2 −1      ha2           · · · ha2 +N−2 
            sα = det (hαi −i+j ) =          ..        ..           ..         ..  
                                                                                                  (1)
                                              .         .               .       .  
                                                                                   
                                         haN −N+1 haN −N+2           ···     haN
Here
                                  α = (a1 ≥ a2 ≥ · · · ≥ aN ≥ 0)

denotes a partition (possibly terminated by a string of zeros), sα denotes the associated
Schur function, and hi = hi (x1 , · · · , xm ) has its usual meaning (i.e. the sum of all mono-
mials in x1 , · · · , xm of total degree i; in particular, this is 1 if i = 0, and 0 if i < 0 ).

                                                  3
    Let us denote the Grothendieck ring of polynomial representation-functors of the
group-scheme GLC by GLC ∧ (Caution: The results in the present paper relevant to the
Zelevinsky complex, are only asserted in characteristic 0—this is signalled by our choice
of C as groundfield. On the other hand, many of the results obtained below concerning
the Verma-Shapovalov element, are valid for arbitrary ground-ring. Finally, only the Lie
algebra AN is here studied.)
    A fruitful heuristic principle in the representation-theory of GLC and the symmetric
groups, is that whereby identities involving symmetric polynomials can in many cases be
re-interpreted as equations in the Grothendieck ring GLC ∧ . Let us now examine the result
of applying this principle to the equation (1) above:
    In this heuristic manner, there is strongly suggested the existance of a complex in
the Grothendieck ring GLC ∧ , which is to be an exact sequence, such that equating to 0
its Euler-Poincare characteristic, yields precisely the Jacobi-Trudi identity (1). Over the
last 25 years, a number of experts (discussed in further detail in §3.1) have considered the
construction of such a complex. This project seems to have been initiated by A. Lascoux in
[Las]; however, the complex constructed by Lascoux, unlike the later Zelevinsky complex,
has differentials which are basis-dependent, (utilizing the combinatorics of Young tableaux)
and so are not GL(V )-linear. These various attempts to construct such a complex, have
produced the following mixed results:
    The terms in these complexes may be precisely specified, in a simple fashion for
which all authors seem in agreement; the precise definitions of the differentials in these
complexes has been more problematical, and it is (in the present author’s opinion) only
the work of Zelevinsky in [Zel] which has first succeeded in producing mathematically
acceptable constructions of these differentials as natural transformations. One of the main
purposes of the present paper, is that of rendering more transparent the construction of
these differentials, utilizing properties (to be established in Chapter Two below) of Weyl
polarizations. This work logically divides into two parts:
1) We shall construct explicitly linear transformations which play the role of the differentials
in these complexes. This will be done in §3.1 below, and this construction uses nothing of
the machinery of Verma modules and the homomorphisms between these. These results
appear to be quite new (except for the very special explicit results of Verma for the case
N = 3 of 3-part partitions, explained in Doty [Doty,pp.134–136], which agree with the
present more general results—as will be verified below in §3.2 ).

                                               4
2)In Chapter Four, the explicit maps furnished by this ’elementary’ construction will be
proved to coincide precisely, with the maps provided by Zelevinsky in terms of the the-
ories of Verma[Verma1,2], Bernstein-Gel’fand-Gel’fand[BGG] and Shapovalov[Shap]. To
the present author’s best knowledge, it is only with the work of Zelevinsky that such a
comparison becomes possible— there was in this sense no specific complex in GLC ∧ in
existence earlier, for which such comparison could make sense. It is for this reason that
it seems appropriate to use here the terminology ‘Zelevinsky complex’. Some important
later work by Akin, Doty and Maliakas, developing these ideas of Zelevinky, may be found
in [Akin1,2], [Doty2] and [Mal]. In particular, the present paper is heavily indebted to the
observation of Akin (in [Akin2,p. 418]) relating the differentials in the Zelevinsky complex
to the Verma-Shapovalov elements—this will be discussed further in §3.3 below.

         In the present author’s opinion, there should exist a more direct combinatorial proof
that the complex constructed in §3.1 is exact. At present, the only proof in the author’s
possession, involves the detour (presented in Chapter Four below) through the theory of
Verma modules and the work of Zelevinsky. One benefit of this detour is the explicit
formula, presented in §3.3 below, expressing (as mentioned earlier) the action on S ⊗N of
each Verma-Shapovalov element for AN as a Z-linear combination of Weyl polarizations.

                     Chapter 1 Weyl’s Multi-Polarization Operators

                                         §1.1 Notation
                                                                         N
         Throughout the following paper, the ground-field will be C.         will always denote
N
    C.   Let N be a positive integer.We denote by N the set {1, ..., N } and by S ⊗N the functor
(on the category of complex vector-spaces and C-linear transformations) which assigns to
each complex vector-space V , the complex vector-space

                                 S ⊗N V = SV ⊗ SV ⊗ · · · ⊗ SV
                                          |       {z          }
                                                     N factors

(where SV is the usual symmetric algebra on V ). Similarly, we define Λ⊗N to be the
functor given by
                                 Λ⊗N V = ΛV ⊗ ΛV ⊗ · · · ⊗ ΛV
                                         |       {z          }
                                                     N factors

For i, j ∈ N , we denote as usual by Ei,j the N × N matrix whose only non-zero entry
is a 1 in row i and column j. We denote by AN the enveloping algebra of gl(N, C), and

                                                 5
by (AN )0 the enveloping algebra of sl(N, C) (considered as a subalgebra of AN ). In all
computations in the present paper, permutations will act on the left of elements, and
linear transformations will act on the left of (column) vectors; thus compositions of linear
transformations and of permutations are to be read right-to-left.

                          §1.2 Elementary Polarization Operators

      If i and j are integers between 1 and N , there is defined a natural transformation

                                            Di,j : S ⊗N V → S ⊗N V                                           (1.2.1)

(the elementary polarization operator), as follows. (We review this well-known concept in
some detail, in preparation for its generalization in the next §.)
      We recall two definitions for these Di,j , the first only meaningful if V is finite-
dimensional over a ground-field of characteristic 0, the second valid for an arbitrary module
V over an arbitrary commutative ground-ring — and with both definitions equivalent for
finite-dimensional V over a field of characteristic 0.
      Suppose first that V is a finite-dimensional complex vector-space, with C-basis

                                                  B = (x1 , . . . , xM )

B induces C-algebra isomorphisms

                                           φB : SV ≃ C[X1 , . . . , XM ]                                     (1.2.2)

and
                                                      (1)            (1)         (N)            (N)
                    ΦB : S ⊗N V ≃ C[X1 , . . . , XM ; . . . ; X1                       , . . . , XM ]       (1.2.2a)
                       (1)             (N)
(where, in (1.2.2a), X1 , . . . , XM denote M N independent indeterminates over C). These
maps will usually be treated implicitly as identifications. With the identification (1.2.2a)
we then define, for a1 , . . . , aN any natural numbers, the restriction of Di,j to S a1 ⊗. . .⊗S aN
to be given by
                          M
                          X      (i)        ∂                                           ′               ′
                 Di,j =         Xk              (j)
                                                      : S a1 ⊗ . . . ⊗ S aN → S a1 ⊗ . . . ⊗ S aN            (1.2.3)
                          k=1          ∂Xk

where we have set                               (
                                                      ai + 1,       if l = i
                                     a′l   =          aj − 1,       if l = j
                                                      al            if l 6= i or j .

                                                                6
                                                                                                                            (i)
      (We set Dij |S a1 ⊗ · · · ⊗ S aN = 0 if aj = 0.) Note that while the operations Xk
        ∂
and      (j)   on S ⊗N of course depend on B, the combination (1.2.3) is readily verified to be
      ∂Xk
independent of the choice of basis B. Here is a basis-free equivalent definition, which does
not require that V be finite-dimensional:
      Let V be an arbitrary module over an arbitrary commutative ring R.
      Suppose first that i < j; then the natural transformation Di,j may be equivalently
defined (combinatorially rather than in the explicit form of a differential operator) as the
operator
                                                                        ′                       ′
                                 Di,j : S a1 ⊗R · · · ⊗R S aN → S a1 ⊗R · · · ⊗R S aN

which maps

                                       (1)                       (2)                        (N)
       σ (1) ⊗ · · · ⊗ σ (N) = (v1 · . . . · va(1)
                                                1
                                                   ) ⊗ (v1 · . . . · va(2)
                                                                        2
                                                                           ) ⊗ (v1                  · . . . · va(N)
                                                                                                                 N
                                                                                                                    )   (1.2.4)

               (p)
(with all vq         ∈ V ) into the element
               aj
               X                       (j)                     (j)       d(j)
                     σ (1) ⊗ · · · ⊗ (vλ · σ (i) ) ⊗ · · · ⊗ (v1 · . . . vλ · . . . · va(j)
                                                                                         j
                                                                                            ) ⊗ · · · ⊗ σ (N)
               λ=1

with a precisely similar definition (except that the order of the two main parentheses is
reversed) if i > j—while if i = j, Di,i acts on S a1 ⊗ · · · ⊗ S aN as multiplication by ai .
      In all three cases, Di,j operates on an element

                                          (1)                               (N)
                                 ω = (v1 · . . . · va(1)
                                                      1
                                                         ) ⊗ · · · ⊗ (v1          · . . . · va(N)
                                                                                               N
                                                                                                  )

like this:
                                                           (j)
      In all possible ways remove a factor vλ , where 1 ≤ λ ≤ aj , from the j-th tensorand
                                             (j)
σ (j) in ω, and re-insert this vλ into the i-th tensorand; then add all the aj results thus
obtained.

      EXAMPLE:
      D13 (x1 x2 x3 ⊗ y1 ⊗ z1 z2 ) = x1 x2 x3 z1 ⊗ y1 ⊗ z2 + x1 x2 x3 z2 ⊗ y1 ⊗ z1
      and
      D11 (x1 x2 x3 ⊗ y1 ⊗ z1 z2 ) = 3x1 x2 x3 ⊗ y1 ⊗ z1 z2

      (Note: Some authors prefer to say the same thing in still a third more high-falutin’
way, by expressing these elementary polarizations (in the obvious way) in terms of the

                                                             7
component

                                                        a
                                                        X
              S a V → S a−1 V ⊗ V, x1 ⊗ · · · ⊗ xa 7→     (x1 ⊗ · · · x̂i · · · xa ) ⊗ xi
                                                        i=1


of the comultiplication map of the Hopf algebra SV .)
    We assume,for the rest of this section, that the ground-ring is C. Using any of the
preceding equivalent definitions for Di,j , it is readily verified that these elementary polar-
ization operators on S ⊗N V obey the commutation relations

                                [Dij , Dkl ] = δjk Dil − δil Dkj

which imply the existence of an action P of AN on S ⊗N by natural transformations,
uniquely specified by
                                        P (Eij ) = Dij .

In fact, we thus obtain, it is well-known, a natural Lie-algebra monomorphism (here to be
referred to as the Capelli injection)

                        C : AN → Nat Tsf(S ⊗N , S ⊗N ), Ei,j 7→ Di,j .                      (1.2.5)


    We shall, for the remainder of this paper, treat the Capelli injection as an identifi-
cation. In particular, this paper will always identify Di,j = P (Ei,j ) (the natural
transformation on S ⊗N ) with Ei,j ∈ AN . (Usually, the notation Ei,j will be used for
both.)
    In the next sub-section, the Weyl multi-polarization will be defined by specifying its
image (via C) as a natural endomorphism of S ⊗N .

    CAUTION: For fixed V, the action of AN on S ⊗N V by C-linear transformations,
need not be faithful; it is for this reason that we shall instead use the faithful action by
natural endomorphisms of the functor S ⊗N ( i.e., work in terms of ‘generic’ V.)


                      §1.3 Multi-polarization Operators on S ⊗N

    We now turn to certain somewhat intricate operations on S ⊗N , for whose construction
the earliest source known to the present author is H.Weyl (cf.[Weyl,p.39]).

                                               8
    Let ΠN                                                                     2
         ± ) denote the free Abelian group (written additively) on the set of N matrices
Ei,j explained in §1.1. Thus the elements in ΠN
                                              ± are of the form
                                    X
                              σ=           σi,j Ei,j     (all σi,j ∈ Z );                (1.3.1)
                                   i,j∈N


each such σ may also be regarded as an N × N matrix ||σi,j || with integer entries.
    Those σ for which all σi,j ≥ 0 will be called N-shifts; the set of N-shifts will be
denoted by ΠN . (Thus, ΠN is the free Abelian semi-group on the set of Ei,j ’s.) An
element σ in ΠN
              ± will be called effective if all σi,j are non-negative (i.e., if σ is an N -shift)
and non-effective otherwise.
    In [Weyl, loc.cit.], Weyl associates (in a slightly different notation) to every N -shift
σ ∈ ΠN , a transformation
                                    P (σ) : S ⊗N V → S ⊗N V

which is now to be defined, and which we shall call the Weyl polarization operator
associated to σ; we shall also sometimes refer to these as multi-polarization opera-
tors. They include, as a special case, the elementary polarization operators discussed in
the preceding section.
    It will be convenient, for the N -shift given by (1.3.1), to set
                                                 Y
                                        σ! =            (σi,j !)                         (1.3.2)
                                                i,j∈N


(and to define σ! to be 0 if σ is non-effective.)
    Again, (as in §1.2) we shall give two definitions (equivalent where both are defined).
The first, that given in [Weyl, loc.cit.]; cf. also (Fulton and Harris[FH, pp.514–515])
requires that V be a finite-dimensional complex vector-space,and involves a choice of basis
for V .The second is defined for V an arbitrary module over an arbitrary commutative ring.

    DEFINITION 1.3.1
    Consider first the case that V is a finite-dimensional complex vectorspace, with C-basis

                                       B = (x1 , . . . , xM )

(so M =dim V ). As before, we use B to define the endomorphisms (1.2.2) and (1.2.2a).
Now write (in the commutative semi-group ΠN )

                              σ = Ei1 ,j1 + Ei2 ,j2 + · · · + EiL ,jL .

                                                   9
Then we define the non-normalized Weyl polarization

                                             P0 (σ) : S ⊗N V → S ⊗N V

to be the endomorphism of S ⊗N V given by:
                 M X
                 X M                 M
                                     X         (i )   (i )        (i )     ∂        ∂              ∂
      P0 (σ) =                 ···           Xk11 Xk22 · · · XkLL          (j )     (j )
                                                                                           ...     (j )
                                                                                                          (1.3.3)
                 k1 =1 k2 =1         kL =1                               ∂Xk11    ∂Xk22          ∂XkLL

There is (as will become apparent) some advantage to considering instead the normalized
Weyl polarizations
                                                1      def
                                                P (σ) = (
                                                   )P0 (σ)                                                (1.3.4)
                                                σ!
(In particular, it is with this normalization that Th.2.3.1 below becomes valid.)
     When mention is made below simply of Weyl polarizations, these normalized polariza-
tions P (σ) are always to be understood. Although P0 (σ) and P (σ) are basis-independent
and natural in V , these facts are perhaps not obvious at this stage (but will be immediate
corollaries of Th. 2.3.1 below).


     REMARKS ON NOTATION: Weyl in [Weyl, loc.cit.] uses the notation

                                              ∆i1 ,j1 ∆i2 ,j2 · · · ∆iN ,jN

for the expression (1.3.3), which he calls a quasi-composition, remarking that (unlike the
ordinary composition Di1 ,j1 · · · DiN ,jN ) it is unchanged by rearrangement of the factors. It
seems perhaps more lucid to use instead a notation such as P0 (σ) for (1.3.3), particularly
since it is not always true that

                     P0 (Ei1 ,j1 + Ei2 ,j2 )(= ∆i1 ,j1 ∆i2 ,j2 in Weyl’s notation)

is the composite of Di1 ,j1 = P0 (Ei1 ,j1 ) and Di2 ,j2 = P0 (Ei2 ,j2 ).
     Weyl’s original notation (which was elegantly suited to his proof in [Weyl,Chapter
II, §4] of the Capelli identity) seems in the spirit of the ’umbral’ notation of nineteenth
century invariant theory, in which ’symbolical products’ occur, i.e. objects which look like
products but are not, and require re-interpretation.
     Also, the additive notation we have adopted in ΠN , has the advantage of avoiding
confusion between e.g. the N -shift

                                      E1,2 + E2,3 = E2,3 + E1,2 ∈ ΠN

                                                             10
and the elements
                                          E1,2 E2,3 6= E2,3 E1,2

in the enveloping algebra AN .


     By the weight vector wt(σ) of an N -shift σ, will be meant the N -tuple

                                      wt(σ) = (wt1 (σ, . . . , wtN (σ)                              (1.3.5)

where
                               N
                               X              N
                                              X
                  wti (σ) =          σi,j −         σj,i                                           (1.3.5a)
                               j=1            j=1

                          = (ith row-sum of σ, minus the ith column-sum )

For a1 , a2 , · · · , aN any natural numbers, it is readily verified that P (σ) maps

                     S a1 ⊗ · · · ⊗ S aN → S a1 +wt1 (σ) ⊗ · · · ⊗ S aN +wtN (σ)                    (1.3.6)

(This is 0 if any ai + wti (σ) = bi is negative, in accordance with the usual convention that
S b V = 0 if b < 0.)
                PN
      Note that i=1 wti (σ) = 0.

     Now let us drop the assumption that V is finite-dimensional. Our next goal is to give
a second definition of P (σ) using combinatorial concepts rather than partial derivatives
(but agreeing, as will be proved below, with Def. 1.3.1 where the latter has been defined.)

Definition 1.3.2. If V is a module over the commutative ring R, and if

                                              α = (a1 , . . . , aN )

is any N -tuple of non-negative integers, then in order to define the restriction

                               P (σ, α) := P (σ)|(S a1 V ⊗ · · · ⊗ S aN V )

its action is to be given on the generating elements

                         (1)      (1)                              (N)     (N)
                  ω = (x1 · x2 · . . . · x(1)
                                          a1 ) ⊗ · · · ⊗ (x1             · x2    · . . . · x(N)
                                                                                            aN )


                                                           11
            (q)
(with all xp elements of V ), by the following rule:
Namely: P (σ, α) acts on ω by moving (in all possible ways) an unordered collection of
σi,j letters x from the j-th tensor factor of ω to the i-th, for all i and j between 1 and
N — NO LETTER BEING MOVED TWICE. The results are then summed, to obtain
P (σ)ω.


      (For the time being, we shall refer to the endomorphisms given by Definition 1.3.1
as differential polarizations, and those given by Definition 1.3.2 as combinatorial
polarizations.This distinction is only a temporary one, since in Section 2.3 these two
definitions will be proved equivalent where both are defined. Also, the preceding somewhat
breezy version of Definition 1.3.2 will be restated more formally in Section 1.4.)
      Note that (1.3.6) is clearly still the type of P (σ), if P (σ) is interpreted in the sense
of Def.1.3.2.
      Perhaps it will be helpful at this point to give some illustrative examples for Definition
1.3.2:

      EXAMPLE 1.3.1
      If
                                   σ1 = E1,2 + 2E13 + 3E32 ∈ Π3 ,

i.e. if                                                         
                                                  0 1          2
                                           σ1 =  0 0          0,
                                                  0 3          0
then σ1 has for weight-vector

                            wt(σ1 ) = (3 − 0, 0 − 4, 3 − 2) = (3, −4, 1)

and the combinatorial polarization

            P (σ1 , (a1 , a2 , a3 )) : S a1 V ⊗ S a2 V ⊗ S aN V → S a1 +3 ⊗ S a2 −4 ⊗ S a3 +1

is, (in accordance with Definition 1.3.2), the map which takes

                       ω = (x1 · . . . · xa1 ) ⊗ (y1 · . . . · ya2 ) ⊗ (z1 · . . . · za3 )

                                                               a3
                                                                           a2 −1
                                                                                    
(all x’s, y’s and z’s in V) into the sum of all a2 ·           2        ·     3         terms obtained by moving:

                                                      12
one letter y from the second tensorand into the first (corresponding to the entry (σ1 )1,2 =
1), two letters z from the third tensorand into the first (corresponding to (σ1 )1,3 = 2), and
three letters y from the second tensorand to the third(corresponding to (σ1 )3,2 = 3), no
letter being moved twice.
     In other words, P (σ1 )ω is to equal the sum
     X                                     y1 · · · ya2
                                                                                                             
          (yj1 zk1 zk2 x1 · · · xa1 ) ⊗ (                 ) ⊗ (yJ1 yJ2 yJ3 z1 · · · zc
                                                                                     k1 · · · zc
                                                                                               k2 · · · za3 ) ,
                                          yj1 yJ1 yJ2 yJ3

extended over the indexing set indicated by
                                      X                   X                 X

                                   1≤j1 ≤a2 1≤J1 <J2 <J3 ≤a2 1≤k1 <k2 ≤a3
                                             j1 ∈{J
                                                / 1 ,J2 ,J3 }


     REMARKS:
     A)We employ in this formula, (for ease of notation), two quite equivalent methods
for denoting the deletion of factors from a product: in the second tensorand deletion of
yj1 yJ1 yJ2 yJ3 is indicated as a division, while in the third tensorand, deletion of zk1 zk2 is
indicated by the usual “∧” notation. We could just as well have written these the other
way around.
     B)If a2 < 4 then this sum is empty, and in accordance with the usual conventions for
an empty sum, P (σ1 )ω = 0.

     EXAMPLE 1.3.2
If                                                       
                                                2     1
                                     σ2 =                     and α = (a1 , a2 )
                                                1     0
then wt(σ2 ) = (0, 0),and

                                P (σ2 , α) : S a1 V ⊗ S a2 V → S a1 V ⊗ S a2

is the map which sends
                                   ω = (x1 · . . . · xa1 ) ⊗ (y1 · . . . · ya2 )

into the sum
                   X            X         X
                                                    (yj x1 · · · xbi · · · xa1 ) ⊗ (xi y1 · · · ybj · · · ya2 )
              1≤I1 <I2 ≤a1 1≤i≤a1 1≤j≤a2
                           i∈{I
                            / 1 ,I2 }


                                                              13
      Note the effect of the diagonal entry (σ2 )11 = 2 in σ2 , is to select (in all possible
ways), an unordered pair of letters {xI1 , xI2 } in the first tensorand (both I1 and I2 being
distinct from i1 ), whereupon we proceed to leave these two letters untouched. (We may as
                                                                              
well suppose I1 < I2 .) Thus P (σ2 ) differs simply by the scalar factor a12−1 from P (σ3 )
where                                                              
                                                              0 1
                                                  σ3 =
                                                              1 0
—i.e.,

                                                          
                                                    a1 − 1
                                      P (σ2 , α) =          P (σ3 , α)
                                                       2
where
                                 X       X
                P (σ3 , α)ω =                    (yj x1 · · · xbi · · · xa1 ) ⊗ (xi y1 · · · ybj · · · ya2 ) .
                                1≤i≤a1 1≤j≤a2


                                                §1.4 σ-selections

      We next need to restate Definition 1.3.2 somewhat more formally. For this purpose,
and also for later computations, the following notations will be convenient:
      Let R be a fixed commutative ground-ring, and let V be an arbitrary R-module.
Recall from §1.1 the notation
                                                  N = {1, ..., N }

For any map
                                                     x:a→V

we define
                                          def
                                  x[[ a ]] = x(1) · x(2) · . . . · x(a) ∈ S a V

Note that such elements span S a V over R; and that similarly (for all non-negative integers
a1 , · · · , aN )
                                             S a1 V ⊗ · · · ⊗ S aN V

is spanned over R by the set of all elements of the form

                    ω = x(1) [[ a1 ]] ⊗ · · · ⊗ x(N) [[ aN ]]                                                    (1.4.1)
                      = (x(1) (1) · . . . · x(1) (a1 )) ⊗ · · · ⊗ (x(N) (1) · . . . · x(N) (aN ))

(where, for 1 ≤ i ≤ N , x(i) is an arbitrary map ai → V ).

                                                          14
      More generally, for any sub-set E of a, say

                       E = {e1 , · · · , eL } ⊆ a ,      with e1 , · · · , eL distinct,

and any map
                                                x:a→V ,

we define
                                    def
                            x[[E]] = x(e1 ) · x(e2 ) · . . . · x(eL ) ∈ S L V

Definition 1.4.1. Let

                               σ ∈ ΠN , α = (a1 , a2 , · · · , aN ) ∈ NN ;

then by a σ-selection from α will be meant a collection

                                          {Ci,j : i and j ∈ N }

such that, (for all i between 1 and N ), C1,i , C2,i , . . . , CN,i are pairwise disjoint subsets of
ai , and such that (for all i and j between 1 and N ), σi,j is the cardinality of Ci,j . We
denote by                                              
                                                       α
                                                       σ
the set of all such.

      NOTE: Given such a σ-selection
                                                                  
                                            ι                     α
                                    ι=    {Ci,j   : i, j ∈ N } ∈                            (1.4.2)
                                                                  σ

it will be convenient to set, for 1 ≤ i ≤ N ,
                                                                    N
                                                                    [
                                    ι def                                  ι
                                   C0,i =    {1, . . . , ai } − (         Cj,i )            (1.4.3)
                                                                    j=1

and
                                                            N
                                                            X
                                                def
                                          σ0,i = ai −             σj,i                      (1.4.4)
                                                            j=1

Note that thus each ai is the disjoint union of

                                           ι      ι              ι
                                          C0,i , C1,i , · · · , CN,i ,

                                                      15
and that
                                                      ι
                                                   #(C0,i ) = σ0,i

The cardinality of                                      
                                                        α
                                                        σ
is then given by
                         YN
                        α                                 ai !
                     #    =
                        σ     σ1,i ! · . . . · σN,i ! · (ai − σ1,i − · · · − σN,i )!
                                   i=1


    Let us now express P (σ)ω (where ω is given by eqn.(1.4.1)), in terms of the notation
just explained. Recall that Def.1.3.2 spoke of “moving (in all possible ways) · · · σi,j letters
x from the j-th tensor factor of ω to the i-th, for all i and j between 1 and N — NO
LETTER BEING MOVED TWICE. The results are then summed, to obtain P (σ)ω.”
    Clearly, such a ‘possible way’ of moving the letters of ω, is furnished precisely by a
σ-selection                                                      
                                                       ι         α
                                                ι=    Ci,j    ∈
                                                                 σ
which instructs us to move the σi,j letters

                                           x(j) (e) where e ∈ Ci,j
                                                               ι



from the j-th tensor factor of ω to the i-th, thus obtaining a result which we shall denote
by ω ι , and whose precise value is given by:

                                             def
                                         ω ι = (ω ι )1 ⊗ · · · ⊗ (ω ι )N                       (1.4.5)

where (for all i between 1 and N ), we set

                                    N
                                    Y
                         ι   def
                      (ω )i = (           x(j) [[Ci,j
                                                  ι
                                                      ]]) · x(i) [[C0,i
                                                                    ι
                                                                        ]] ∈ S ai +wti (σ) V   (1.4.6)
                                    j=1


(cf. eqn.(1.3.5a) in §1.3). With the notation thus defined, the following equation may then
be regarded as the deluxe version of Definition (1.3.2):

                                                        def
                                                              X
                                             P (σ)ω =                 ωι .                     (1.4.7)
                                                              ι∈(α
                                                                 σ)



                                                         16
    NOTE: Our formulas sometimes contain expressions of the form P (σ ′ ) where σ ′ is
an N × N matrix over Z, not all of whose entries are ≥ 0. (In the terminology introduced
in the beginning of §1.3, σ ′ is a non-effective element of ΠN
                                                             ±)
    To avoid any possible ambiguity, let us agree always to set, in such a case,

                                          P (σ ′ ) = 0 if any σi,j
                                                               ′
                                                                   <0                                      (1.4.8)


Section 2 The Product of a Multi-polarization by an Elementary Polarization

               §2.1 The Recurrence for Combinatorial Polarizations

    NOTE:Throughout this subsection, all multi-polarizations P (σ) considered are to be
understood in the sense of Definition 1.3.2 of the preceding §1.3. (We shall consider in
the following subsection 2.2, multi-polarizations in the sense of Definition 1.3.1, i.e. in the
sense of Weyl’s original definition.)

Theorem 2.1.1. Let σ ∈ ΠN and let i,j be distinct integers between 1 and N .Then
                                                        N
                                                        X
        Ei,j P (σ) = (σi,j + 1)P (Ei,j + σ) +                  (σi,k + 1)P (σ + Ei,k − Ej,k )              (2.1.1)
                                                        k=1

    PROOF: By an obvious symmetry of the situation under study (namely, via the
action of the symmetric group on N letters, upon the tensor product of N copies of SE),
it is evident that it suffices to prove (2.1.1) in the special case i = 2, j = 1.
    Thus, it suffices to verify that
                                                         N
                                                         X
     E2,1 P (σ)ω = (σ2,1 + 1)P (E2,1 + σ)ω +                    (σ2,k + 1)P (σ + E2,k − E1,k )ω            (2.1.2)
                                                         k=1

for every generating element ω of the form (1.4.1). Let us then consider (utilizing the
notation explained in §1.4)
                                 X                   X
            E2,1 P (σ)ω =               E2,1 ω ι =           E2,1 [(ω ι )1 ⊗ (ω ι )2 ⊗ · · · ⊗ (ω ι )N ]
                                ι∈(α
                                   σ)                ι∈(α
                                                        σ)


E2,1 ω ι is the sum of all terms obtained by removing one letter u from the first tensorand

                                    ι
            (ω ι )1 = x(1) [[ a1 − C2,1            ι
                                        − · · · − CN,1 ]] · x(2) [[C1,2
                                                                    ι
                                                                        ]] · . . . · x(N) [[C1,N
                                                                                             ι
                                                                                                 ]]        (2.1.3)
                                                                     N
                                                                     Y
                        (1)              ι              ι
                   =x         [[ a1 −   C1,1   −···−   CN,1 ]]   ·         x(k) [[C1,k
                                                                                   ι
                                                                                       ]]
                                                                     k=1

                                                        17
of ω ι , and inserting it instead into the second tensorand

                                                                                           N
                                                                                           Y
     (ω ι )2 = x(1) [[C2,1
                       ι
                           ]] · x(2) [[ a2 − C1,2
                                              ι      ι
                                                  − C3,2            ι
                                                         − · · · − CN,2 ]] ·                    x(k) [[C2,k
                                                                                                        ι
                                                                                                            ]]   (2.1.3a)
                                                                                          k=3


—let us denote by T (ω ι , u) the term thus obtained. That is to say, for each letter u in
(2.1.3) we set
                                        (ω ι )1
                      T (ω ι , u) = (           ) ⊗ (u · (ω ι )2 ) ⊗ (ω ι )3 · · · ⊗ (ω ι )N                      (2.1.4)
                                          u
and we then have
                                                              X X
                                   E2,1 P (σ)ω =                            T (ω ι , u)                           (2.1.5)
                                                             ι∈(α  u
                                                                σ)


(the inner sum being extended over all letters u in (2.1.3).)
    The next step is to decompose (2.1.5) into N + 1 sub-sums, (according to where u
comes from), as follows:
    If 1 ≤ k ≤ N , let us define S(k) to be the sum of those terms in (2.1.5) for which
u = x(k) (e) with e ∈ C1,k
                       ι
                           , i.e. we set

                                     def
                                            X              X
                              S(k) =                                  T (ω ι , x(k) (e(k) ))                     (2.1.6a)
                                                                ι
                                           ι∈(   α
                                                 σ   )   e(k) ∈C1,k


(Here we adopt, as always, the convention which sets empty sums equal to 0— thus S(k)
               
is to be 0 if α                  ι
              σ is empty, or if C1,k = ∅.) Similarly, we set

                                     def
                                            X               X
                               S(0) =                                 T (ω ι , x(1) (e(0) ))                     (2.1.6b)
                                                                ι
                                           ι∈(   α
                                                 σ   )   e(0) ∈C0,1


Thus we have the desired decomposition:

                                                                      N
                                                                      X
                                           E2,1 P (σ)ω =                    S(k)                                  (2.1.7)
                                                                      k=o


    To complete the proof of the theorem, it thus suffices to prove the two following
equations:
                                   S(0) = (σ2,1 + 1)P (σ + E2,1 )ω                                                (2.1.8)

and (for 1 ≤ k ≤ N )
                              S(k) = (σ2,k + 1)P (σ + E2,k − E1,k )ω                                              (2.1.9)

                                                              18
    First, suppose 1 ≤ k ≤ N , and consider S(k). In proving (2.1.9), we must consider
separately two cases, according to whether or not σ + E2,k − E1,k has all entries non-
negative.
CASE ONE:              σ + E2,k − E1,k ∈ ΠN
    In order to establish (2.1.9), we next construct a (σ2,k + 1)-to-one correspondence,
mapping the                                              
                                                         σ
                                                     [#    ] · σ1,k
                                                         α
terms                                                        
                                     ι    (k)    (k)         α
                              {T (ω , x         (e     ):ι∈    , e(k) ∈ C1,k
                                                                         ι
                                                                             }
                                                             σ
of the sum (2.1.6a) which makes up S(k), into the
                                                    
                                     σ + E2,k − E1,k
                                 #
                                            α
terms                                                                    
                                         κ                σ + E2,k − E1,k
                                    {ω : κ ∈                               }
                                                                α
whose sum is P (σ + E2,k − E1,k )ω, in such a way that equality holds for each pair of
corresponding terms.
    Namely, for every pair                       
                                                 α
                                             ι∈    , e(k) ∈ C1,k
                                                             ι
                                                                                                      (2.1.10)
                                                 σ
let us define
                                  κ = Φk (ι, e(k) ) = {Ci,j
                                                        κ
                                                            : i, j ∈ N }

to be the (σ + E2,k − E1,k )-selection specified by
                            κ           ι      (k)
                            C2,k = C2,k ∪ {e }
                              C κ = C1,k ι
                                            − {e(k) }                                                 (2.1.11)
                            1,kκ       ι
                              Ci,j = Ci,j ,                           otherwise.

(In other words, κ is obtained from ι by moving e(k) from C1,k
                                                           ι       ι
                                                               to C2,k .)
    Then, for the selection κ thus defined, (1.4.6) obviously becomes
    κ
    (ω )1 = x(1) [[ a1 − {e(k) } − C2,1
                                     ι               ι
                                         − . . . − CN,1 ]] · x(2) [[C1,2
                                                                     ι
                                                                         ]] · . . . · x(N) [[C1,N
                                                                                               ι
                                                                                                    ]]
   
   
   
                                                                                        N
                                                                                        Y
       κ       (1)     (k)      ι      (2)          ι        ι                 ι
     (ω )2 = x [[{e } ∪ C2,1 ]] · x [[ a2 − C1,2 − C3,2 − · · · − CN,2 ]] ·                  x(l) [[C2,l
                                                                                                       ι
                                                                                                         ]]
   
   
   
                                                                                       l=3
      κ        ι        ι
     (ω )l = Ci,j = (ω )l if 3 ≤ l ≤ N

                                                            19
which implies (using (2.1.3), (2.1.3a) and (2.1.4)) that

                                      T (ω ι , x(k) (e(k) ) = ω κ

    Given any                                                    
                                                       α
                                     κ∈
                                              σ + E2,k − E1,k
there are precisely σ2,k + 1 pairs (2.1.10) such that

                                           κ = κ(ι, e(k) )

—given by letting e(k) range through the

                               (σ + E2,k − E1,k )2,k = σ2,k + 1

             κ
elements of C2,k , and then taking, for each such e(k) , the C ι ’s uniquely determined by
(2.1.11). Hence we obtain
                                     X          X
                            S(k) =                      T (ω ι , x(k) (e(k) ))
                                                  ι
                                        σ)
                                     ι∈(α  e(k) ∈C1,k
                                                           X
                                 = (σ2,,k + 1)                              ωκ
                                                  κ∈(σ+E      α
                                                                        )
                                                            2,k −E1,k

                                 = (σ2,k + 1)P (σ + E2,k − E1,k )ω

(as was to be proved.)
CASE TWO:            σ + E2,k − E1,k 6∈ ΠN
    Since σ ∈ ΠN by hypothesis, it must be that σ1,k = 0, whence S(k), being an empty
sum, is equal to zero.Since also P (σ + E2,k − E1,k ) = 0, (2.1.9) again holds trivially in this
case.

    Thus (2.1.9) holds in all cases. We have still to prove (2.1.8). The proof is essentialy
the same, with these two variations:
We must replace (2.1.10) by
                      
                       α
                 ι∈       , e(0) ∈ C1,0
                                    ι           ι
                                        = a1 − C1,1    ι
                                                    − C1,2            ι
                                                           − . . . − C1,N             (2.1.10a)
                       σ
and we must replace (2.1.11) by
                                            (    κ      ι
                                                C2,1 = C2,1 ∪ {e(0) }
                            (2.1.11a)
                                                 κ      ι
                                                Ci,j = Ci,j otherwise

                                                  20
noting that for each                                                 
                                                         α
                                             κ∈
                                                      σ + E21
there are precisely σ21 + 1 pairs (2.1.10a) such that (2.1.11a) holds (given by letting e(0)
                                       κ
range through the σ21 + 1 elements of C2,1 .)
                          This completes the proof of the theorem.


Definition 2.1.2. An N -shift σ will be called reduced if all its diagonal entries σi,i
vanish (for 1 ≤ i ≤ N ). The reduced form σ red of any N -shift σ, is the N -shift specified
by
                                                  n
                                                      σi,j , if i 6= j;
                                  (σ red )i,j =
                                                      0      otherwise.

Proposition 2.1.3. Let V be a module over a commutative ring R. Suppose a1 , . . . , aN
are non-negative integers,and that

                             σ ∈ ΠN , ω ∈ S a1 V ⊗ · · · ⊗ S aN V

Then
                                       N 
                                       Y       P                            
                                          ai −                       σj,i
                          P (σ)ω =                            j6=i
                                                                                · P (σ red )ω          (2.1.12)
                                       i=1
                                                         σi,i

[Note: For an example of this proposition, cf. Example 1.3.2]
PROOF: Let us compare
                                   X                                                 X
                       P (σ)ω =           ω ι , with P (σ red )ω =                              ωκ .
                                                                                        α
                                  ι∈(α
                                     σ)                                            κ∈(σ red )


We have the epimorphism                                
                                              α      α
                                          φ:     →
                                              σ     σ red
which maps a σ-selection ι into the σ red -selection

                                                        κ
                                           κ = φ(ι) = {Ci,j }

defined by                                            ι
                                      κ              Ci,j , if i 6= j
                                     Ci,j    =
                                                     ∅      if i = j.

                                                         21
Clearly ω κ = ω ι .
Given                                                               
                                                              α
                                                  κ∈
                                                             σ red
                                               ι
we obtain all ι with φ(ι) = κ by selecting as Ci,i , for each i from 1 to N , an arbitrary
σi,i -element subset of
                                                        [
                                                                  κ
                                                ai −             Cj,i .)
                                                       1≤j≤N
                                                         j6=i

     Thus, φ is an M -to-1 map, where
                                                N 
                                                Y       P                          
                                                   ai −              j6=i   σj,i
                                        M=                                             ,
                                                i=1
                                                               σi,i

and so we have, as asserted,
                                     X                        X
                        P (σ)ω =            ωι = M ·                     ω κ = M P (σ red )ω .
                                                                 α
                                    ι∈(α
                                       σ)                κ∈(σ red )




Theorem 2.1.4. Let σ ∈ ΠN and let 1 ≤ i ≤ N . Then
                                                                                   N
                                                                                   X
                         Ei,i P (σ) = (σi,i + 1)P (Ei,i + σ) + (                           σi,k )P (σ)      (2.1.13)
                                                                                   k=1

     (It is to be noted that the coefficients in (2.1.1) and (2.1.13) do not depend, as one
might have expected, on a1 , · · · , aN , but only on σ.)

PROOF:
     It suffices, by the same symmetry argument as before, to prove the special case
                                                                                       N
                                                                                       X
                      E1,1 P (σ)ω = (σ1,1 + 1)P (E1,1 + σ)ω + (                              σ1,k )P (σ)ω   (2.1.14)
                                                                                       k=1

(where ω is given by (1.4.1)).
     Let us now set
                                          N 
                                          Y        P                     
                                  ′ def       ai −               σj,i
                              P     =                     j6=i
                                                                             · P (σ red )ω
                                          i=2
                                                        σi,i

Note that (by (1.4.4))
                                  a1 − σ2,1 − · · · − σN,1 = σ1,1 + σ0,1

                                                         22
Hence, Prop.2.1.3 implies
                                                                      
                            a1 − σ2,1 − · · · − σN,1    ′    σ1,1 + σ0,1
                  P (σ)ω =                             P =                 P′               (2.1.15)
                                     σ1,1                        σ1,1
Replacing σ by σ + E1,1 in this last equation yields
                                                          
                                               σ1,1 + σ0,1
                            P (σ + E1,1 )ω =                P′                              (2.1.16)
                                                σ1,1 + 1
    Recall that E1,1 acts on
                                      S a1 V ⊗ · · · ⊗ S aN V                               (2.1.17)

as multiplication by a1 . Since ω lies in (2.1.17), it follows by (1.3.6) (which as noted applies
both for Def. 1.3.1 and for Def.1.3.2) that

                         P (σ)ω ∈ S a1 +wt1 (σ) V ⊗ · · · ⊗ S aN +wtN (σ) V

Here wti (σ) is defined by (1.3.5a); we note in particular

                a1 + wt1 (σ) = a1 − (σ2,1 + · · · + σN,1 ) + (σ1,2 + · · · + σ1,N )         (2.1.18)
                                         N
                                         X
                              = σ0,1 +         σ1,k
                                         k=1

From the preceding, we readily deduce
                                                                                   
                                                                        σ1,1 + σ0,1
    E1,1 P (σ)ω = [a1 − (σ21 + · · · + σN,1 ) + (σ1,2 + · · · + σ1,N ]               P′     (2.1.19)
                                                                            σ1,1
    In the identity                                            
                                        A                        A
                               (B + 1)                = (A − B)                             (2.1.20)
                                       B+1                       B
replace A by σ11 + σ01 , B by σ11 . We obtain
                                                                  
                                   σ1,1 + σ0,1           σ1,1 + σ0,1
                       (σ1,1 + 1)                = σ0,1
                                    σ1,1 + 1                 σ1,1
whence (using also eqns.15, 16 and 19:)
                                 N
                                 X                     
                                            σ0,0 + σ0,1
         E1,1 P (σ)ω = (σ0,1 +      σ1,k )               P′
                                                σ1,1
                               k=1
                                                     XN                        
                                    σ1,1 + σ0,1                       σ1,1 + σ0,1
                     = [(σ1,1 + 1)                  +(    σ1,k )σ0,1               ] · P′
                                      σ1,1 + 1                            σ1,1
                                                           k=1
                                                  N
                                                  X
                      = σ1,1 P (σ + E1,1 )ω + (         σ1,k ))P (σ)ω
                                                  k=1

                                                  23
which completes the proof of the theorem.

                    §2.2 The Recurrence for Differential Polarizations

     We assume, throughout the present sub-section, that a specific C-basis

                                             B = {x1 , . . . , xM }

has been chosen for V, with all Weyl polarizations defined via Def.1.3.1, by means of B.
(Only in the following §2.3 will we prove, using the results of the present sub-section, that
the differential Weyl polarizations are basis-independent.)
     Actually, for the purposes of the present sub-section, computations go a bit more
easily with the non-normalized differential Weyl polarizations P0 (σ):

Theorem 2.2.1. Let i and j be distinct integers between 1 and N ; let σ ∈ ΠN .Then the
four following equations hold:

                                                         N
                                                         X
                         Ei,j P0 (σ) = P0 (Ei,j + σ) +         σj,k P0 (σ + Ei,k − Ej,k )     (2.2A)
                                                         k=1


                                                         N
                                                         X
                         P0 (σ)Ei,j = P0 (Ei,j + σ) +          σk,j P0 (σ + Ek,j − Ek,i )     (2.2B)
                                                         k=1

                                                                    N
                                                                                 !
                                                                    X
                              Ei,i P0 (σ) = P0 (Ei,i + σ) +               σi,k       P0 (σ)   (2.2C)
                                                                    k=1

                                                                    N
                                                                                 !
                                                                    X
                              P0 (σ)Ei,i = P0 (Ei,i + σ) +                σk,j       P0 (σ)   (2.2D)
                                                                    k=1

     PROOF:
Suppose
                                         σ = Ei1 ,j1 + · · · + EiL ,jL ,                      (2.2.1)

with all i’s and j’s in N (so that σi,j is the number of λ between 1 and L for which
(iλ , jλ ) = (i, j) ).
     For every

                                   (1)        (1)           (N)            (N)
                         F ∈ C[X1 , · · · , XM ; · · · ; X1       , · · · , XM ] = S ⊗N V ,

                                                       24
we have (by eqn.(1.3.3))

                                 M
                                 X                                    X
                                         (i)       ∂                                (i )      (i )         ∂ LF
         Ei,j P0 (σ)F = (              Xk              (j)
                                                           )                     Xk11 · · · XkLL        (j )          (j )
                                 k=1           ∂Xk             k1 ,···,kL ∈M                         ∂Xk11 · · · ∂XkLL

which is in turn equal to the sum A + B of

                                 X                 (i)     (i )             (i )             ∂ L+1 F
                   A=                          Xk Xk11 · · · XkLL                      (j)    (j )         (j )
                         k,k1 ,···,kL ∈M                                           ∂Xk ∂Xk11 · · · ∂XkLL

and
           X           X                  (i)           (i )           \(i )       (i )                    ∂ LF
   B=                             δiλ ,j Xkλ       ·   Xk11      · · · Xkλλ · · · XkLL          (j )           (j )          (j )
         1≤λ≤L k1 ,···,kL ∈M                                                                 ∂Xk11 · · · ∂Xkλλ · · · ∂XkLL

Clearly A = P0 (Ei,j + σ)F , while
                          X
                 B=                P0 (Ei1 ,j1 + · · · +                   Ei,j         + · · · + EiL ,jL )F
                         iλ =j
                                                                           | {z λ}
                        1≤λ≤L                                         replacing Eiλ ,jλ

(in which the selected term Ei,jλ replaces the term Eiλ ,jλ = Ej,jλ in (2.2.1).) Thus,
                                                                           X
                     Ei,j P0 (σ) = P0 (Ei,j + σ) +                                 P0 (σ + Ei,jλ − Ej,jλ )                   (2.2.2)
                                                                        iλ =j
                                                                       1≤λ≤L


Now,given any k between 1 and N , there are precisely σj,k values of λ for which iλ =
j, jλ = k, and each contributes the same term P0 (σ + Ei,k − Ej,k ) to the sum on the right
side of eqn.(2.2.1); from which eqn.(2.2A) is immediate.
      The proof of (2.2B) is precisely similar. For the same reasons, it suffices to examine
here only one of (2.2C) and (2.2D); let us choose the first. Then with notation as before,

                                 M
                                 X                                 X
                                         (i)       ∂                               (i )       (i )         ∂ LF
          Ei,i P0 (σ)F = (             Xk              (i)
                                                           )                     Xk11 · · · XkLL        (j )          (j )
                                 k=1           ∂Xk             k1 ,···,kL ∈M                         ∂Xk11 · · · ∂XkLL

which is the sum A′ + B ′ of

                    X              (i)      (i )               (i )                ∂ L+1 F
        A′ =                     Xk Xk11 · · · XkLL                        (i)      (j )        (j )
                                                                                                       = P0 (Ei,i + σ)F
               k,k1 ,···,kL ∈M                                        ∂Xk ∂Xk11 · · · ∂XkLL

                                                                      25
and
              X         X                   (i) (i )      \(i )       (i )                          ∂ LF
      B′ =                          δiλ ,i Xkλ Xk11 · · · Xkλλ · · · XkLL             (j )            (j )   (j )
             1≤λ≤L k1 ,···,kL ∈M                                                   ∂Xk11 · · · ∂Xkλλ · · · ∂XkLL
              X          X            (i )       (i )                   ∂ LF
         =                          Xk11 · · · XkLL        (j )           (j )               (j )
              iλ =i k1 ,···,kL ∈M                       ∂Xk11 · · · ∂Xkλλ · · · ∂XkLL
             1≤λ≤L


Thus ,
                                                                  N
                                                                               !
                                         X                        X
                             B′ =               P0 (σ)F =               σi,k       P0 (σ)F
                                        iλ =i                     k=1
                                       1≤λ≤L

and so finally,
                                                                       N
                                                                       X
                             Ei,i P0 (σ) = P0 (Ei,i + σ) + (                 σi,k )P0 (σ)
                                                                       k=1

This completes the proof of Th.2.2.1.
      We obtain the analogous formulas for the normalized differential polarizations

                                                            1
                                                P (σ) =        P0 (σ)
                                                            σ!

as a trivial consequence of the preceding; note the first and third of the following formulas,
correspond precisely with the results in §2.1 for combinatorial polarizations. (Let us note,
however, that the proofs of the corresponding results in §2.1 were rather more intricate
than those in the present sub-section.)

Corollary 2.2.2.         Let σ ∈ ΠN and let i,j be distinct integers between 1 and N .Then the
four following equations hold:

                                                               N
                                                               X
              Ei,j P (σ) = (σi,j + 1)P (Ei,j + σ) +                  (σi,k + 1)P (σ + Ei,k − Ej,k )          (2.2.2A)
                                                               k=1
                                                               N
                                                               X
              P (σ)Ei,j = (σi,j + 1)P (Ei,j + σ) +                   (σk,j + 1)P (σ + Ek,j − Ek,i )          (2.2.2B)
                                                               k=1
                                                               N
                                                               X
               Ei,i P (σ) = (σi,i + 1)P (Ei,i + σ) + (               σi,k )P (σ)                             (2.2.2C)
                                                               k=1
                                                               N
                                                               X
               P (σ)Ei,i = (σi,i + 1)P (Ei,i + σ) + (                σk,i )P (σ)                             (2.2.2D)
                                                               k=1

                                                          26
      PROOF: Dividing both sides of (1.4A) by σ!, and observing that
                                          Y
                        (σ + Ei,j )! =          (σ + Ei,j )p,q = σ!(σi,j + 1 , )
                                          p,q


and that
                                                                σi,k + 1
                                (σ + Ei,k − Ej,k )! = σ! ·
                                                                  σj,k
we immediately obtain (2.2.2A).
      The proof of (2.2.2B) is precisely similar. Similarly, dividing both sides of (2.2C),
(2.2D) by σ! , we obtain (2.2.2C),(2.2.2D). This completes the proof of Cor.2.2.2.
      Finally,as an immediate consequence of the preceding corollary, we obtain the com-
mutators given by:

Corollary 2.2.3. Let i and j be distinct integers between 1 and N ; let σ ∈ ΠN .Then
[Ep,q , P (σ)] = A − B, where

                                  N
                                  X
                            A=          (σp,k + 1)P (σ + Ep,k − Eq,k ) ,
                                  k=1


and
                                  N
                                  X
                            B=          (σk,q + 1)P (σ + Ek,q − Ek,p ) ,
                                  k=1

Also, we have                                                       !
                                                  N
                                                  X
                           [Ep,p , P (σ)] =             (σp,k − σk,q ) P (σ)              (2.2.3)
                                                  k=1


      REMARK: Suppose i 6= j. If σj,k = 0, then the term P0 (σ + Ei,k − Ej,k ) occurs with
zero coefficient in (2.2.A), but P (σ + Ei,k − Ej,k ) occurs with positive coefficient σi,k + 1 in
(2.2.2A) (which is a scalar multiple of (2.2A).) To explain this apparent discrepancy, note
that here (σ + Ei,k − Ej,k )j,k = −1, so by the convention adopted in §1.3,

                                    P (σ + Ei,k − Ej,k ) = 0 .



             §2.3 Equivalence of the Two Kinds of Multi-polarizations

                                                     27
Theorem 2.3.1. Let σ ∈ ΠN , and let V be a finite- dimensional complex vector-space,
with C-basis
                                            B = {x1 , . . . , xM } .

Let
                                    P B (σ, V ) , resp. P (σ, V )

denote the natural transformations

                                                S ⊗N → S ⊗N

constructed respectively in Definition 1.3.1 (of differential Weyl polarizations) and Defini-
tion 1.3.2 (of combinatorial Weyl polarizations). Then,

                                            P B (σ, V ) = P (σ, V )                                    (2.3.1)

PROOF:
      By the weight W (σ) of an N -shift σ, will be meant the sum of all its entries:
                                                         N X
                                                         X N
                                                   def
                                        W (σ) =                     σi,j
                                                         i=1 j=1

We now shall prove (2.3.1) by an induction on W (σ):
Assume first:        W (σ) = 1
      Here there exist i and j in N such that σ = Ei,j , and so (2.3.1) becomes the assertion
that (as already remarked in §1.2) the two definitions for the elementary polarizations
Di,j = P (Ei,j ) coincide whenever they both make sense.

Assume next :         1 < W (σ) and (2.3.1) holds for all N -shifts of weight < W (σ)
      There exist i,j in N such that σi,j > 0; we consider two cases, according as i 6= j or
i = j.
      Suppose first that i and j are distinct.We may write

                                                σ = σ ′ + Ei,j

with σ ′ effective. Replacing σ by σ ′ in eqns. (2.1.1) and (2.2A) we obtain the two equations
                                                   N
                                                   X
                                        ′                   ′
             σi,j P (σ, V ) = Ei,j P (σ , V ) −           (σi,k + 1)P (σ ′ + Ei,k − Ej,k , V ) ,
                                                   k=1
                                                     N
                                                     X
                 B                  B       ′                   ′
            σi,j P (σ, V ) = Ei,j P (σ , V ) −                (σi,k + 1)P B (σ ′ + Ei,k − Ej,k , V )
                                                     k=1

                                                         28
All N -shifts on the right sides of these equations, have weights one less than that of σ, so
the induction hypothesis implies these right sides are equal. Hence also the left sides are
equal. Since σi,j is by assumption non-zero, (2.3.1) follows in the present case.
    Suppose next that i = j. Replacing σ by the effective N -shift

                                            σ ′ = σ − Ei,i

in eqns.(2.1.13) and (2.2C), we obtain the two equations

                                                              N
                                                              X
                                                   ′                  ′
                       σi,i P (σ, V ) = Ei,i P (σ , V ) −           (σi,k )P (σ ′ , V ) ,
                                                              k=1
                                                                   N
                                                                   X
                     σi,i P B (σ, V ) = Ei,j P B (σ ′ , V ) −              ′
                                                                         (σi,k )P B (σ ′ , V )
                                                                   k=1


and conclude the argument as before.
    This completes the proof of Theorem 2.3.1.

    From this point on, it is no longer necessary (over the ground-field C ) to distinguish
between the two types of multi-polarizations.
    The following useful corollary is an immediate consequence of the preceding argument:

Corollary 2.3.2. Let σ be an N -shift of weight W > 1, and let i,j in N be such that σi,j
is non-zero. Then there exist: effective N -shifts (all of weights W-1)

                                            σ1 , σ2 , · · · , σL

(for some non-negative integer L, which may be 0) and positive integers mk (1 ≤ k ≤ L)
such that
                                                                    L
                                                                    X
                        σi,j · P (σ) = Ei,j P (σ − Ei,j ) −                 mk P (σk ) .
                                                                    k=1

If, in addition, σ has the property

                               for all i, j ∈ N , σi,j 6= 0 ⇒ i > j .

then σ1 , · · · , σL may be chosen, all also to have this property.

    This in turn immediately implies:

                                                       29
Corollary 2.3.3. For every N -shift σ there exists unique P ′ (σ) in AN such that, for every
complex vector-space V, the Weyl polarization

                                    P (σ, V ) : S ⊗N V → S ⊗N V

coincides with multiplication by P ′ (σ).


          Chapter 3 APPLICATIONS OF WEYL POLARIZATIONS

          §3.1 DIFFERENTIALS IN THE ZELEVINSKY COMPLEX

    As promised in the introduction, we shall now utilize the Weyl polarizations, to ob-
tain new and quite explicit formulas, for the differentials in certain natural complexes
which (in Zelevinsky’s metaphor, [Zel,p.152]) ‘materialize’ the Jacobi-Trudi identity. This
application involves a train of thought spanning roughly a century and a half, and one
which has (it would seem) not yet reached its full conclusion, despite relevant work by (in-
ter alia) Akin[Akin1,2], Buchsbaum, Doty[Doty and Doty2], Lascoux[Las], Maliakas[Mal],
Nielsen[Nielsen], Verma[Verma1,2], Woodcock[Wood] and Zelevinsky[Zel].

    Before discussing the differentials in the Zelevinsky complex, we must begin by dis-
cussing the individual terms:
    Let us rewrite the Jacobi-Trudi identity (1) in the Introduction, as

                                        X               N
                                                        Y
                                 sα =          sgn(π)         hai −i+π(i)            (3.1.1)
                                        π∈SN            i=1

Reading this in the Grothendieck ring GLC ∧ , sα corresponds to the Weyl functor V 7→ V α
(in the terminology of Carter and Lusztig,[CL]) while the symmetric polynomial
                   N
                   Y
                         hai −i+π(i) = ha1 −1+π(1) ha2 −2+π(2) · · · haN −N+π(N)
                   i=1

occurring in eqn.(3.1.1), is the character of the functor

                 V 7→ S a1 −1+π(1) V ⊗ S a2 −2+π(2) V ⊗ · · · ⊗ S aN −N+π(N) V       (3.1.2)

(where as usual, SV = ⊕S i V denotes the symmetric algebra on the finite-dimensional
complex vector-space V .) It will be convenient to denote by SYMα V , the vector space

                                  S a1 V ⊗ S a2 V ⊗ · · · ⊗ S aN V ,

                                                  30
so that (3.1.2) may thus be denoted by SYMα−ρ+π(ρ) V —where we set

                       ρ = (1, 2, · · · , N ) and π(ρ) = (π(1), π(2), · · · , π(N )) .

    All this suggests that, (temporarily forgetting about the differentials), we may hope
to obtain a complex ZEL(α) = ZEL(α, V ) in GLC ∧ , the alternating character-sum of
whose terms corresponds as desired to the sum in (3.1.1), if we define the i-th term of this
complex to be
                                                   M
                                 ZELi (α, V ) =             SYMα−ρ+π(ρ) V                         (3.1.3)
                                                   π∈SN
                                                   l(π)=i


(where l(π) denotes the number of inversions of a permutation π in SN .) It will be
convenient to denote the individual summands in (3.1.3) by
                 def
 ZELπ (α, V ) = SYMα−ρ+π(ρ) V = S a1 −1+π(1) V ⊗ S a2 −2+π(2) V ⊗ · · · ⊗ S aN −N+π(N) V
                                                                                                 (3.1.3a)

    Thus we are led (all the authors cited above appear to agree on this) to seek for
differentials dk which will render exact the following complex:
                        dk+1                   d            d                d
    ZEL(α, V ) : · · · −→ ZELk (α, V ) −→
                                        k        2
                                          · · · −→ ZEL1 (α, V ) −→
                                                                 1
                                                                   ZEL0 (α, V )                   (3.1.4)

and for which d1 has cokernel the Weyl module V α Here we also wish to require the
differentials dk to be natural transformations—something required by all but one of the
authors cited.

    There is a further generalization in ([Zel]); namely, Zelevinsky next drops the require-
ment that the N -tuple
                                            α = (a1 , · · · , aN )

represents a partition, requiring only that the a’s be integers— the complex (3.1.4) con-
structed by Zelevinsky remains exact in this greater generality (while if in addition α
is a partition, then coker(d1 ) = V α ). The remainder of the present discussion is to be
understood in this greater generality.

    To specify the differentials
                         M                                                       M                    ′
 dl : ZELl (α, V ) =             SYMα−ρ+π(ρ) V → ZELl−1 (α, V ) =                          SYMα−ρ+π       (ρ)
                                                                                                                V
                        π∈SN                                                     ′
                                                                              π ∈SN
                        l(π)=l                                               l(π ′ )=l−1



                                                     31
is the same, as to specify the collection of C-linear transformations

              ′
          dπ,π
           α   : SYMα−ρ+π(ρ) V = S a1 +π(1)−1 V ⊗ S a2 +π(2)−2 V ⊗ · · · ⊗ S aN +π(N)−N V
                          ′                    ′                     ′                   ′
          → SYMα−ρ+π          (ρ)
                                    V = S a1 +π (1)−1 V ⊗ S a2 +π (2)−2 V ⊗ · · · ⊗ S aN +π (N)−N V

for all
                                    π, π ′ ∈ SN with l(π) = l, l(π ′ ) = l − 1                        (3.1.5)

(We omit l from our notation for these maps, since by (3.1.5) l is determined by π.)
                                                                 ′
     We divide the construction of the maps dπ,π
                                             α   into four smaller parts, as follows:
                                                                                 ′
 A. We must specify, for precisely which pairs π, π ′ the map dπ,π
                                                               α   is to be non-zero.
 B. To each such pair π, π ′ meeting condition A, Akin assigns a signature ±, according to
     the rule to be described below.
                                                                         ′
 C. When π, π ′ meet condition A, we shall express dπ,π
                                                    α   as a C-linear combination of Weyl
     polarizations P (σ)—thus we must specify precisely which P (σ) appear in this linear
     combination. This condition will be independent of α, and such shift-matrices σ will
     be called subordinate to the pair π, π ′ .
                                                                                     ′
 D. Finally, when P (σ) has been designated as occurring in dπ,π
                                                             α , we must specify the
     precise numerical coefficient with which it occurs. (It will depend on α, and will be an
     integer if all ai are integers—indeed, will be a product of certain binomial coefficients
     and factorials, as specified below.)

                                                             ′
                                     A. WHEN IS dπ,π
                                                 α   NON-ZERO?
     Let (3.1.5) hold.
     In the complex to be constructed here (which will be proved later to coincide with that
                                                                 ′
constructed by Zelevinsky ) the partial maps dπ,π
                                              α   are defined to be 0 unless π ′ precedes π
in the Bruhat order (This Ansatz was suggested to the author by Verma in a conversation.)
     It is well known (cf., for example, [Mathas,p.2,Prop.1.3]) that this holds if and only if
there exist i,j such that

                                    1 ≤ i < j ≤ N, π(i) > π(j), π ′ = π(i, j)                         (3.1.6)

     We shall call (π, π ′ ) an arrow-pair if these conditions (3.1.5), (3.1.6) are satisfied.
(The relation of such arrow-pairs to the theory of maps between Verma modules of AN
will be discussed below in §3.4)

                                                        32
         B. AKIN’S NORMALIZATION OF THE BGG SIGNATURE

    Let AN denote the set of all arrow-pairs of SN , as defined above. In [BGG], it is
proved that there exists a map
                                       s : AN → {1, −1}

with this property:
    For every set of four arrow-pairs

                        (i1 ,j1 )     (i2 ,j2 )           (i3 ,j3 )   (i4 ,j4 )
                      w1 −→ w2 , w2 −→ w4 , w1 −→ w3 , w3 −→ w4 ,                       (3.1.7)

in A, we have
                         s(w1 , w2 )s(w2 , w4 )s(w1 , w3 )s(w3 , w4 ) = −1              (3.1.8)

We shall call such a map a BGG-signature for AN . (Although the treatment in [BGG],
and so some of the following discussion in this section, make sense in much greater gener-
ality, for our present purposes it suffices to restrict to the consideration of AN . ) [BGG]
calls a configuration such as (3.1.7) a square; we denote (3.1.7) by the diagram

                                      w1 −→              w2
                                       (i ,j(i1),j1 )     (i ,j )                     (3.1.9)
                                       y 3 3               y 2 2
                                      w3 −→               w4
                                              (i4 ,j4 )


    More generally, if A′N is a subset of AN , by a partial BGG-signature for A′N , will
be meant a map
                                       s : A′N → {1, −1}

such that (3.1.8) holds for every square (3.1.9), for which all four arrow-pairs lie in A′N .

    The BGG resolutions, for the case AN , are only completely specified once one of the
(many) BGG signatures for AN has been selected. Because Zelevinsky’s construction in
[Zel] of the complex studied in the present section is obtained from the BGG resolution,
it also is only specified up to the choice of a BGG signature.

    This ambiguity is perhaps not very serious, but Akin in [Akin1,2] has shown one
specific way to choose these matters in a completely unique fashion —let us pause here to
sketch his normalization, since it is fairly short, and the author has not seen it presented as
an explicit algorithm in the literature. Akin defines a specific BGG-signature, as follows:

                                                    33
     For every permutation w ∈ SN , let P (w) denote the set of permutations w which
precede w in the Bruhat order—i.e., such that there exists a chain

                                      (i0 ,j0 )                      (il ,jl )
                              w = w0 −→ w1 −→ · · · −→ wl −→ w

of arrow-pairs in SN , beginning with w and ending with w. (We include w in P (w).)

     Let                                           
                            1, 2, · · · , N − 1, N
                      w̃ =                            : i 7→ N + 1 − i
                             N, N − 1, · · · , 2, 1
                                                       
denote the element in SN of maximal length N2 . (Note that thus P (w̃) = AN and
P (I) = {I}.)
     Let Σ denote a chain

                                   Σ : w̃ = w(N ) → . . . → w0 = I                  (3.1.10)
                                              2


     N
         
of   2
             arrow-pairs in SN , such that each arrow-pair

                                                  (ip ,ip +1)
                                           wp+1     −→          wp

in the chain Σ is associated with an elementary transposition (ip , ip + 1).
     Then as Akin notes implicitly, the existence proof in [BGG], actually gives a construc-
tive algorithm for computing— from the datum Σ—a BGG-signature sΣ for SN , by the
inductive procedure next to be explained.
                              
    Suppose that 0 ≤ p < N2 , and that a partial BGG-signature sp has been given for
P (wp ). Then the argument in ([BGG],pp.56 and 57) in fact shows that the following rules
furnish a well-defined extension of sp (involving no choices other than that of Σ) to a
partial BGG-signature sp+1 for P (wp+1 ):
                (q,r)
     Let w −→w′ be an arrow-pair, with w (hence w′ ) in P (wp+1 ). In order to compute
sp+1 (w, w′ ), we must consider four cases:
     Case I : w ∈ P(wp )
     Then also w′ ∈ P (wp ) Since we wish sp+1 to extend sp , we are forced to define

                                                     def
                                      sp+1 (w, w′ ) = sp (w, w′ )

     Case II : w ∈
                 / P(wp ), (q, r) = (ip , ip + 1)

                                                    34
      Here [BGG] defines sp+1 (w, w′ ) to be +1.(This Ansatz implies the rules for the two
following Cases.)
                   / P(wp ), w′ ∈
      Case III : w ∈            / P(wp ), (q, r) 6= (ip , ip + 1)
                  / P(wp ), w′ ∈ P(wp ), (q, r) 6= (ip , ip + 1)
      Case IV : w ∈
      In both of these two cases, it follows from ([BGG], Lemma 11.3 on p.53), that
                                             (ip ,ip +1)
                                       w       −→          w(ip , ip + 1)
and
                                             (ip ,ip +1)
                                       w′      −→          w′ (ip , ip + 1)
are arrow-pairs, and that w(ip , ip + 1) and w′ (ip , ip + 1) lie in P (wp ).
      Thus, in Case III, sp+1 (w, w′ ) is well-defined by
                                       def
                         sp+1 (w, w′ ) = −sp (w(ip , ip + 1), w′ (ip , ip + 1))
(i.e., by the requirement, that the product of the edge-signatures of the following square
                                   w       −→         ′
                                                       w
                                    +1                +1
                                    y                  y
                                                    ′
                             w(ip , ip + 1) −→ w (ip , ip + 1)
is to be −1.)
      Similarly, in Case IV we must set
                             def
              sp+1 (w, w′ ) = −sp (w(ip , ip + 1), w′ (ip , ip + 1))sp (w′ , w′ (ip , ip + 1)

      Continuing inductively, this algorithm gives the desired BGG-signature sN(N−1)/2 =
sΣ on P (w̃) = AN

      We shall (following Akin) utilize a canonical choice of the chain Σ, which is perhaps
sufficiantly explained by giving the case N = 4:
            1234 −→ 1243
                    | {z } −→ 1423
                              |    −→
                                    {z 1432} −→ 4132
                                                |    −→ 4312
                                                         {z −→ 4321}                            (3.1.11)
                       float 3          float 2                               float 1
      The associated BGG-signature will be called the Akin signature, and will be denoted
by sgnA .

   C.     THE SHIFT-MATRICES SUBORDINATE TO AN ARROW-PAIR
      Let (π, π ′ ) be an arrow-pair, so in particular there exist unique integers i, j satisfying
(3.1.6). We define the multiplicity of (π, π ′) to be the positive integer
                                            r = π(i) − π(j) > 0                                 (3.1.12)
                             ′
      We shall define dπ,π
                       α   to be a suitable Z-linear combination of those Weyl polarizations
P (σ), for which σ lies in the set defined as follows:

                                                           35
Definition 3.1.1. Let 1 ≤ i < j ≤ N , and let r be a positive integer. Then we denote by
T ERM (i, j, r) the set of all N -shifts

                                                     σ ∈ ΠN

which satisfy the following three conditions:
 I) σp,q = 0 unless i ≤ q < p ≤ j.
         Pj
II) r = l=i+1 σl,i
III) For all k strictly between i and j, we have

                                               j                  j
                                               X                  X
                                                         σl,k =         σk,l                  (3.1.13)
                                                   l=i            l=i


     (i.e., σk,i + · · · + σk,k−1 = σk+1,k + · · · + σj,k .)
     Also, it will be convenient to denote by Rk (σ) the common value of both sides of
     eqn.(3.1.13).

     In particular, if i, j, r are related as above to an arrow-pair (π, π ′ ) , then we shall say
that the elements of the set T ERM (i, j, r) just defined, are subordinate to (π, π ′ ).
     Let us again note specifically, that this condition on σ is totally independent of α, and
indeed only depends on (i, j) and r.
                                                                                          ′
             D. THE NUMERICAL COEFFICIENT OF P (σ) IN dπ,π
                                                       l

     Let (π, π ′) be an arrow-pair, with i, j determined by (2.2), and with multiplicity
r = π(i) − π(j). Let
                                        α = (a1 , ..., aN ) ∈ CN ,

and let σ be an N -shift subordinate to (π, π ′ ).

Definition 3.1.2. Under the preceding hypotheses, we define the amplitude

                                               hσ; π, π ′i ∈ C

to be the integer given by

                                        j−1
                                        Y                                          
                           ′                                             π(i) − π(k)
                   hσ; π, π i = r! ·               Rk (σ)!(r − Rk (σ))!                       (3.1.14)
                                                                          r − Rk (σ)
                                       k=i+1


                                                          36
(with the understanding the product in (3.1.14) is to be taken equal to 1 if it is empty, i.e.
if j = i + 1.)

     Note:This amplitude is independent of α, depending (as the notation indicates) only
on the N-shift σ and the arrow-pair (π, π ′). This amplitude is an integer, which may be
negative.

                                                                                 ′
                       CONSTRUCTION OF THE MAPS dπ,π
                                                 α
                                                                                               ′
     We may now, finally, complete our construction of the natural transformations dπ,π
                                                                                    α ,
and hence of the differentials in the complex (3.1.5), as follows:
     Let (π, π ′) be an arrow-pair, with i, j determined by (2.2), and with multiplicity
r = π(i) − π(j). Let
                                    α = (a1 , ..., aN ) ∈ ZN ,

let V be a complex vectorspace, and let sgn be a BGG-signature for AN (not necessarily
the Akin signature). Finally, let

                       ω ∈ ZELπ (V, α) = S b1 V ⊗ S b2 V ⊗ · · · ⊗ S bN V

(with the b’s determined by (3.1.3a))

     Then we define

                        ′   def
                                                      X
                                      ′
                   dπ,π
                    α,sgn ω = sgn(π, π ) ·                        hσ; π, π ′i · P (σ)ω   (3.1.15)
                                             σ∈T ERM (i,j,r)



     This completes our construction of the complex ZEL(α, V ); we must postpone
till Chapter 4 the proof of the following theorem, which asserts that the result of this
construction is indeed is an exact sequence, (except possibly for its last term) and coincides
completely with the complex obtained by the method of Zelevinsky:

Theorem 3.1.3. With
                                             ′            ′
                                         dπ,π
                                          α   = dπ,π
                                                 α,sgn

given by (3.1.15), let us define the maps dk in (3.1.4) by
                                                 M            ′
                                    dk =                 dπ,π
                                                          α   ;
                                             l(π)=k
                                           l(π ′ )=k−1


                                                 37
then these maps coincide completely with the maps
                          M                                    M                      ′
                 dZEL
                  k   :            SYMα−ρ+π(ρ) V →                         SYMα−ρ+π       (ρ)
                                                                                                V
                          π∈SN                                 ′
                                                              π ∈SN
                          l(π)=k                             l(π ′ )=k−1



constructed by Zelevinsky in [Zel] from the BGG-resolutions for AN (constructed using
sgn.)

    Let us conclude this section by once again emphasizing, that the preceding construc-
tion makes NO use of the theory of Verma modules. By contrast, the proof this construc-
tion yields an exact sequence—at least, the only complete proof available at present to the
author—makes heavy use of the work of Verma, Bernstein-Gel’fand-Gel’fand, Shapovalov
and Zelevinsky.
    We shall next consider some specific examples of the construction just explained.

                     §3.2 SOME ILLUSTRATIVE EXAMPLES

                                         EXAMPLE 3.2.1
    Our first example involves the case N=3. The special case N = 3 of the Zelevinsky
complex (with α a partition) is presented in ([Doty], pp.134–136), where this result is at-
tributed to Verma. In Doty’s complex, the differentials are explicitly furnished as elements
of A3 , but not, of course, expressed in the language of multi-polarizations. Thus, this earlier
data provides an excellent test for our assertions. (Although it is assumed in [Doty] that
α is a partition, in fact these results are valid without the assumption a1 ≥ a2 ≥ a3 ≥ 0.)
As we shall see, the complex presented for N = 3 by Doty and Verma, is in fact precisely
the Zelevinsky complex, normalized by the choice of the Akin signature sgnA .
    Assume then,
                                    N = 3 , α = (a1 , a2 , a3 ) ∈ Z3

and let V denote a finite-dimensional complex vector-space. It will be convenient to denote
the permutation                                                   
                                                   1 2 3
                                          π=
                                                   π1 π2 π3
by [π1 π2 π3].
    Here the Zelevinsky complex ZEL(α, V ) assumes the form

                                         d               d                 d
                          0 → ZEL3 −→
                                    3
                                      ZEL2 −→
                                            2
                                              ZEL1 −→
                                                    1
                                                      ZEL0                                          (1)

                                                    38
with the terms ZELl given by (3.1.3) and (3.1.4) as follows:

        ZEL0 = S a1 V ⊗ S a2 V ⊗ S a3
        ZEL1 = ZEL[213] ⊕ ZEL[132]
               = (S a1 +1 V ⊗ S a2 −1 V ⊗ S a3 V ) ⊕ (S a1 V ⊗ S a2 +1 V ⊗ S a3 −1 V )
        ZEL2 = ZEL[231] ⊕ ZEL[312]
               = (S a1 +1 V ⊗ S a2 +1 V ⊗ S a3 −2 V ) ⊕ (S a1 +2 V ⊗ S a2 −1 V ⊗ S a3 −1 V )
        ZEL3 = ZEL[321] = S a1 +2 V ⊗ S a2 V ⊗ S a3 −2 V

    Having thus computed the terms in (1), let us next turn to the more interesting
question of the differentials. To obtain these, let us go in order through the four steps
explained in §3.1:
    STEP A : A3 consists of the 8 arrow-pairs:
   (
                (1,2)                (2,3)                (1,3)                (2,3)
     τ1 : [213] −→ [123], τ2 : [132] −→ [123], τ3 : [231] −→ [132], τ4 : [231] −→ [213],
               (1,2)                   (1,3)                (1,2)                   (2,3)
     τ5 : [312] −→ [132], τ6 : [312] −→ [213], τ7 : [321] −→ [231], τ8 : [321] −→ [312] .
                                                                                        (3.2.1)
    STEP B : We must next compute the Akin signature sgnA for these 8 arrow-pairs.
For chain (3.1.10) with N =3, we take the Akin choice
                               (2,3)                (1,2)           (2,3)
                     w3 = [321] −→ w2 = [312] −→ w1 = [132] −→ w0 = I

from which the inductive procedure of BGG yields the Akin signatures given in the fol-
lowing table (where the arrow-pairs τi are given by (3.2.1)):
                  i       1    2       3      4     5      6                7   8
               sgnA (τi ) +    +       −      +     +      −                +   +
    (For readers interested in applying the inductive algorithm of §3.1.1 to verify this
table, it may be helpful to note that, setting

                                       Fi = P (wi )\P (wi+1 ) ,

there is induced on S3 the filtration given by:

            F0 = {[123]}, F1 = {[132]}, F2 = {[213], [312]}, F3 = {[231], [321]} )

    STEPS C and D : Here the maps
                                                ′
                                           dπ,π
                                            α   = dα (τ )

                                                    39
(where τ denotes the arrow-pair π → π ′ ) which are furnished by the remaining two steps,
are given in the second row of the following table, while the third row lists the maps dDV (τ )
furnished by Doty and Verma; it is asserted that the second and third rows coincide, i.e.,
that dα (τ ) = dDV (τ ).
        i     1,8 2,7             3                 4          5                 6
     dα (τi ) E2,1 E3,2 E3,1 − P (E3,2 + E2,1 )2P (2E3,2 )2P (2E2,1 )−2E3,1 − P (E3,2 + E2,1 )
    dDV (τi )E2,1 E3,2 E3,2 E2,1 − 2E2,1 E3,2 (E3,2 )2 (E2,1 )2       E2,1 E3,2 − 2E3,2 E2,1
       We chase through the details for the case

                                                  (1,3)
                                        τ3 : [231] −→ [132] ;

it is left as an exercise to any reader so interested, to verify the other entries in this table
by the same straightforward algorithm.
       The natural transformation

                     dα (τ3 ) : ZEL[2, 3, 1] = S a1 +1 V ⊗ S a2 +1 V ⊗ S a3 −2 V           (3.2.2)
                       → ZEL[1, 3, 2] = S a1 V ⊗ S a2 +1 V ⊗ S a3 −1 V

is one of the four constituents of d2 .
       Here                               
                                 123    ′   123
                             π=       ,π =      , (i, j) = (1, 3)
                                 231        132
Hence by (3.1.8), r = π(1)−π(3) = 1. Examination of Def.3.1.1 (in Case C of the preceding
subsection) shows that the 3-shift σ is subordinate to π and π ′ , (i.e., lies in T ERM (1, 3, 1)),
precisely when:
 (i) All σi,j are 0, except possibly σ2,1 , σ3,1 , and σ3,2 .
(ii) σ2,1 + σ3,1 = 1
(iii) σ2,1 = σ3,2
       Hence
                                   T ERM ((1, 3, 1) = {σ1 , σ2 }

with
                                   σ1 = E3,1 , σ2 = E2,1 + E3,2

Thus, dα (τ3 ) is a C-linear combination of P (2E3,1 ) and P (E2,1 + E3,2 ), with the numerical
coefficients next to be determined (via Def.3.1.2 in Step D of the preceding subsection.)

                                                 40
     Consider first
                                                   σ1 = E3,1 .

Here
                                                 R2 (σ1 ) = 0 ,

and eqn.(3.1.15) yields the amplitude
                                                           
                                      ′        π(1) − π(2)   −1
                      < E3,1 ; π, π >= 1!0!1!              =    = −1
                                                    1         1

     Similarly, we have
                                                 R2 (σ2 ) = 1 ,

and so
                                          < E3,2 + E2,1 ; π, π ′ >= 1

Recalling that sgnA (τ3 ) = −1, (3.1.16) gives the entry

                                    dα (τ3 ) = E3,1 − P (E3,2 + E2,1 )                                          (3.2.3a)

in the preceding table.
     It remains to verify that this map coincides, on their common domain

                          ZEL[2, 3, 1] = S a1 V ⊗ S a2 +1 V ⊗ S a3 −1 V ,

with the Doty-Verma map

                         dDV (τ3 ) = [E3,2 E2,1 − 2E2,1 E3,2 ]|ZEL[2, 3, 1]                                     (3.2.3b)

To prove this, it suffices to verify that both maps have the same effect on every element

                           ω = (x1 · · · xa1 +1 ) ⊗ (y1 · · · ya2 +1 ) ⊗ (z1 · · · za3 −2 )
in
                 ZEL[231] = S a1 +1 V ⊗ S a2 +1 V ⊗ S a3 −2 V

(all x’s, y’s and z’s in V ). Let us set

                          aX
                           1 +1

         A := E3,1 ω =            (x1 · · · xbi · · · xa1 +1 ) ⊗ (y1 · · · ya2 +1 ) ⊗ (xi · z1 · · · za3 −2 )
                          i=1

                                                         41
and

          B := P (E3,2 + E2,1 )ω =
               1 +1 aX
              aX     2 +1

          =                 (x1 · · · xbi · · · xa1 +1 ) ⊗ (xi · y1 · · · ybj · · · ya2 +1 ) ⊗ (yj · z1 · · · za3 −2 )
              i=1 j=1


(Note that A and B both lie in ZEL[1, 3, 2] = S a1 V ⊗ S a2 +1 V ⊗ S a3 −1 V .)
       Then direct computation (as explained in §1.2) shows that
                             a1
                             X
   E3,2 E2,1 ω = E3,2              (x1 · · · x
                                             bi · · · xa1 +1 ) ⊗ (xi · y1 · · · ya2 +1 ) ⊗ (z1 · · · za3 −2 ) = A + B
                             i=1

and similarly
                                                     E2,1 E3,2 ω = B

Hence, finally,

         dDV (τ3 )ω = (A + B) − 2B = A − B = E3,1 ω − P (E3,2 + E2,1 )ω = dα (τ3 )ω .


       (Question: Is there some simple rule one could use directly to compute the Akin
signature—or some other specific BGG-signature—rather than the tedious step-by-step
inductive algorithm presented in §3.1?)
                                                  EXAMPLE 3.2.1
       Our next example involves N = 4 and the arrow-pair

                                                                (2,4)
                                                  τ : [2341] −→ [2143]

Let sgn denote an arbitrary choice (not necessarily sgnA ) of BGG-signature on A4 .
       If α = (a1 , a2 , a3 , a4 ) ∈ Z4 , and V varies over complex vector-spaces, then the natural
transformation dα,V (τ ), which maps

                    ZEL[2341](α, V ) = S a1 +1 V ⊗ S a2 +1 V ⊗ S a3 +1 V ⊗ S a4 −3 V

into
                   ZEL[2143] (α, V ) = S a1 +1 V ⊗ S a2 −1 V ⊗ S a3 +1 V ⊗ S a4 −1 V ,

is a component of the differential d3 in ZEL(α, V ) (since [2341] has 3 inversions.) This
mapping is, in fact, that resulting from the action on the A4 -module ZEL[2341](α, V ) of

                                                              42
the following element in A4 (which, it should be noted, is completely independent both of
α and of V ):

       d(τ ) = sgn(τ ) · [4P (2E3,2 + 2E4,3 ) − 2P (E3,2 + E4,3 + E4,2 ) + 2P (2E4,2 )]                      (3.2.5)

(The reader may find it a helpful exercise, to compute (3.2.5), using the algorithm explained
in §3.1.)

      One final bit of propaganda for the efficacy and appropriateness of the Weyl polariza-
tions in such computations: let us examine the precise effect of (3.2.5) on the generating
element

    ω = w ⊗ x ⊗ y ⊗ z = (w1 · · · wa1 +1 ) ⊗ (x1 · · · xa2 +1 ) ⊗ (y1 · · · ya3 +1 ) ⊗ (z1 · · · za4 −3 )

for ZEL[2341] (α, V ):
      Using eqn.(3.2.4) we obtain

                                 dα,V (τ )ω = sgn(τ )(4A − 2B + 2C)

where we have set:
                                   X           X                   x                      y
A = P (2E3,2 + 2E4,3 )ω =                                  w⊗            ⊗ (xi · xi′ ·           ) ⊗ (yj · yj ′ · z) ,
                                                                xi · xi′               yj · yj ′
                                  i<i′         j<j ′
                                i,i′ ∈a2 +1 j,j ′ ∈a3 +1


                                               X            X                x            y
      B = P (E3,2 + E4,3 + E4,2 )ω =                                 w⊗            ⊗ (xi · ) ⊗ (xi′ · yj · z)
                                                           j∈a3 +1
                                                                          xi · xi′        yj
                                               i6=i′
                                            i,i′ ∈a2 +1


and
                                                X                  x
                    C = P (2E4,2 )ω =                      w⊗            ⊗ y ⊗ (xi · xi′ · z)
                                                                xi · xi′
                                                i<i′
                                             i,i′ ∈a2 +1


Note that A, B, C all lie, as they ought to, in

                  ZEL[2143] (α, V ) = S a1 +1 V ⊗ S a2 −1 V ⊗ S a3 +1 V ⊗ S a4 −1 V ,


         §3.3 The action on S ⊗N of the Verma-Shapovalov Elements for AN

      Let g be a semi-simple complex Lie algebra, with h a selected Cartan subalgebra; also
assume selected an ordering for (g, h), with ∆+ the set of positive roots. Let ρ denote half

                                                           43
the sum of the roots in ∆+ . For any positive root α, we denote the associated co-root in
h by hα —so that
                                        sα (λ) = λ − λ(hα )α

for all λ ∈ h∗ . Let N+ denote the nilpotent sub-algebra of g generated by the positive root
spaces, and N− that generated by the negative root spaces.

     For any λ ∈ h∗ , we denote by Iλ , the left ideal in the enveloping algebra A(g) of g,
generated by
                                  ∆+ ∪ {h − λ(h) · 1 : h ∈ h}

Thus the g-module
                                           Vλ := A(g)/Iλ

is precisely the Verma module over g, with highest weight λ. We denote by vλ the image
of 1 in this quotient, (so that Vλ is cyclic on the distinguished highest-weight vector vλ .)

Definition 3.3.1. By a Verma triple for such a g, will be meant an ordered triple
(α, r, λ) satisfying the following four conditions:
 (i) α is a positive root in (g, h).
(ii) λ ∈ h∗
(iii) r is a positive integer
(iv) λ − sα • λ = rα

     REMARK: Here the symbol • designates the “twisted action” of the Weyl group on
h, given by
                                       sα • λ = sα (λ + ρ) − ρ

Thus condition (iv) may be replaced by the equivalent condition

                                           (λ + ρ)hα = r


     It is a well-known result, due to Verma, that given such a triple, there exists a non-zero
g-linear homomorphism
                                            Vλ−rα → Vλ                                  (3.3.1)

unique up to scalar multiples. However, since our purpose here is to express this map as
an explicit Z-linear combination of (the actions of) Weyl polarizations, it is necessary to
select an explicit normalization of this element; Shapovalov has constructed one method
for doing so, as follows:

                                                 44
Definition 3.3.2. Let τ =(α, r, λ) be a Verma triple for g.
By the Verma-Shapovalov element

                                  γ = V S(τ ) = V Sα,r (λ)

for this triple, is meant the element γ in A(N− ) uniquely specified by the two following
conditions:
    VS1)There is a non-zero g-linear map

                                      φ : Vλ−rα → Vλ

such that
                                      φ(vλ−rα ) = γvλ

    VS2)Choose a total ordering << of ∆+ ; say

                     {α1 << α2 << · · · << αm }, where m = #(∆+ )

For each α ∈ ∆+ let Eα be an associated root vector.

    This choice associates to every map π : ∆+ → N a basis element

                             Fπ := (Eα1 )π(α1 ) · · · (Eαm )π(αm )                     (3.3.2)

in the PBW basis for A(N− ) associated with << , namely the basis
                                                     +
                                     {FΠ |Π ∈ (N)∆ } .                                 (3.3.3)

Note in particular the distinguished map

                                     π < r >: ∆+ → N

which maps each of the simple roots to r, and maps all other positive roots to 0. It is then
required that, when the Verma-Shapovalov element γ is expanded as a C-linear combination
of the PBW-basis (3.3.3), the basis vector Fπ<r> shall have coefficient precisely 1.

REMARKS: The first requirement VS1), specifies σ = V S(τ ) uniquely, up to a scalar
multiple. (This is the fundamental result of Verma which is the basis of the present
paper.) Concerning the second requirement, (due it seems to Shapovalov), whose effect is

                                              45
to remove this last ambiguity in the definition of VS(τ ), let us note that this requirement
presupposes two non-obvious facts: 1)The coefficient of Fπ[τ ] is not identically 0 in all
operators satisfying VS1). 2)The requirement VS2) is in fact independent of the particular
choice of total ordering << on ∆+ .
      These two facts may be found proved, in Franklin([Fra,§3 and 4] * for arbitrary semi-
simple Lie algebras, in arbitrary characteristic.
      In a recent clarifying discussion of these matters, the present author was informed by
Verma, that the construction in Verma’s thesis [Verma 1] of a g-homomorphism (3.3.1)
was in fact defined absolutely, not simply up to scalar multiples. This would imply that
the construction in Verma’s thesis supplied an intrinsic method of normalizing (3.3.1).
Below, there will be given a formula (3.3.6), an expression in which will then be verified to
satisfy the two Shapovalov conditions listed above, and hence to coincide with the Verma-
Shapovalov element.The present author does not know the precise relation between these
two methods of normalization (Verma’s and Shapovalov’s), and hence must here leave
open the question of the relations (if any) of formula (3.3.6) below, to the normalization
of (3.3.1) propounded by Verma.

      From now on, for the remainder of the present paper, we shall restrict
ourselves entirely to the Lie algebra

                                            g = slN (C) = AN−1

and to its enveloping algebra (AN )0 .
      In this special case, we choose, (as is usual), the Cartan subalgebra h, to be that
formed by the diagonal N × N matrices of trace 0. The dual h∗ of this is spanned over C
by the N linear functionals λi ( i between 1 and N ) where λi maps any N × N matrix C
in g into its i-th diagonal entry Ci,i . (Thus the λi have sum 0. ) The usual choice here for
the set of positive roots is

                                    ∆+ = {λi − λj : 1 ≤ i < j ≤ N }

and the associated nilpotent subalgebra N+ is that formed by the N × N strictly upper-
triangular matrices over C—so that N− is the Lie algebra formed by the strictly lower-
triangular ones.
                                                                                                  P
  *   Caution: There is a typo in the statement of VS2) on p.66 of [Fra]; in (3),loc.cit.,   r=       ni ǫi   must be
                     P
replaced by   dr =       ni ǫi

                                                       46
       With these choices, it is readily seen that the Verma triples for AN−1 consist of those
ordered triples
                                                                   N
                                                                   X
                                      (α = λi − λj , r, λ =              li λi )
                                                                   i=1

(with 1 ≤ i < j ≤ N, r ∈ Z+ , the li being complex numbers), which satisfy

                                              li − lj − i + j = r                      (3.3.4)

Definition 3.3.3. Let
                                                                   N
                                                                   X
                                      τ = (λi − λj , r, λ =              li λi )
                                                                   i=1

be a Verma triple for AN−1 , and (using Def.3.1.1) let

                                             σ ∈ T ERM (i, j, r) ;

Then we define the amplitude hσ; τ i ∈ C to be

                                       Y 
                                       j−1                                  
                                                                      li − lk
                                                                              
                     hσ; τ i = r! ·            Rk (σ)!(r − Rk (σ))!                    (3.3.5)
                                                                    r − Rk (σ)
                                      k=i+1

       Our goal in the next § will be the proof of:

Theorem 3.3.4. If
                                         τ = (λi − λj = α, r, λ)

is a Verma triple for AN−1 , and if we set

                                                 def
                                        T (τ ) = T ERM (i, j, r)

then
                                                       X
                                      V S(τ ) =                hσ; τ iP (σ) .          (3.3.6)
                                                   σ∈T (τ )



NOTE: As noted by K.Akin in [Akin2, p.418], the maps
                                                           ′
                                                       dπ,π
                                                        α,sgn


for the Zelevinsky complex, are given by precisely the same elements

                                             sgn(π, π ′)V S(π, π ′)

                                                        47
in AN which furnish the corresponding maps in the BGG-resolution. Hence Th.3.3.4
implies (and is apparently rather stronger than) Th.3.1.3.

                 Section 4            Proof of the Assertions in Section 3

    As observed at the end of §3.3, to prove all the assertions in §3, it suffices to prove
Th.3.3.4.
    For the rest of this §, there will be assumed the hypotheses of Th. 3.3.4 ; that is, we
suppose:
                             P
 (i) τ = (λi − λj , r, λ =       li λi ) is a Verma triple for AN−1 ; and we set
(ii) T (τ ) = T ERM (i, j, r) , as defined in Def.3.1.1.
    Note that (i) means that:
1 ≤ i < j ≤ N , r is a positive integer, and

                                          li − lj − i + j = r                         (4.1)


    Then, to complete the proof of Theorem 3.3.4, it suffices to prove that the element γ
in AN , defined by
                                          def
                                                 X
                                        γ =            hσ; τ iP (σ)                   (4.2)
                                                σ∈T (τ )

satisfies (relative to the given Verma triple τ ) the two conditions VS1) and VS2) which,
in Def.3.2.2, characterize the Verma-Shapovalov element V S(τ ).(Here the coefficients

                                                   hσ; τ i

are the numbers given by Def.3.3.3.)
    Unwrapping all this, we see that the goal of proving Th.3.3.4 will have been achieved,
once the three following assertions have been established:
A1 γ · vλ is a maximal vector in Vλ .
A2 This vector γ · vλ has weight λ − rα.
A3 γ satisfies the normalization condition V S2) in Def.3.3.2.
    (Note that, if A1 and A2 are satisfied, then the element γ · vλ in Vλ generates a
sub-module isomorphic to Vλ−rα , from which VS1) is immediate.)
    The next three sub-sections are devoted to the proof, in this order, of these three
assertions.

                                                     48
                   §4.1 Proof That γ · vλ is a Maximal Vector in Vλ

     The purpose of this sub-section is the proof of assertion A1, that is, the proof that:

                            Ep,p+1 · γ · vλ = 0 for 1 ≤ p ≤ N − 1                    (4.1.1)

     In the remainder of this paper, ≡ is always to be understood to mean ≡ modulo the
left ideal Iλ in AN defined in §3.1. In other words, for all γ and γ ′ in AN ,

                            γ ≡ γ ′ if and only if γ · vλ = γ ′ · vλ .

For instance, eq.(4.1.1) is equivalent to the assertion

                                          Ep,p+1 · γ ≡ 0                             (4.1.2)

This in turn is equivalent to the assertion that

                              [Ep,p+1 , γ] ≡ 0 for 1 ≤ p ≤ N − 1                    (4.1.3) ,

since by definition every left multiple in AN of Ep,p+1 lies in Iλ .

                    • Throughout the rest of this sub-section, 1 ≤ p < N .


Our proof of (4.1.3) will proceed in three steps:
We first analyze the commutators

                                          [Ep,p+1 , P (σ)]

for all σ in T ERM (τ ). The results thus obtained will be applied in the second step to
expand [Ep,p+1 , γ] as a linear combination of Weyl polarizations with explicitly described
integer coefficients. In the third step, we shall finally prove (4.1.3) by showing these
coefficients are all 0.

                Step One: Analysis of [Ep,p+1 , P (σ)] for σ ∈ T ERM (τ )
By Cor. 2.2.3, we have
                                   [Ep,p+1 , P (σ)] = A − B                          (4.1.4)

where
                                N
                                X
                           A=         (σp,k + 1)P (σ + Ep,k − Ep+1,k )              (4.1.4a)
                                k=1

                                                49
and
                               N
                               X
                         B=          (σk,p+1 + 1)P (σ + Ek,p+1 − Ek,p )                     (4.1.4b)
                               k=1



      By hypothesis, σ satisfies the conditions of Def. 3.1.1. (in Part C of §3.1). In
particular, condition I) of this definition implies that

                       σp+1,k = 0 if i ≤ k < p + 1 ≤ j does not hold,

in which case
                               (σ + Ep,k − Ep+1,k )p+1,k = −1 ,

so by eq.(1.4.8),
                                    P (σ + Ep,k − Ep+1,k ) = 0 .

Since also σp,p = 0, we obtain

                                                p−1
                                                X
            A = 1 · P (σ − Ep+1,p + Ep,p ) +          (σp,k + 1)(P (σ − Ep+1,k + Ep,k )
                                                k=i


In the same way, we have

                                                j
                                                X
         B = P (σ − Ep+1,p + Ep+1,p+1 ) +              (σk,p+1 + 1)P (σ − Ek,p + Ek,p+1 )
                                               k=p+2


Combining the two preceding equations with (4.1.4), we obtain:

          [Ep,p+1 , P (σ)] = [P (σ − Ep+1,p + Ep,p ) − P (σ − Ep+1,p + Ep+1,p+1 )]+          (4.1.5)
                             p−1
                             X
                         +         (σp,t + 1)(P (σ − Ep+1,k + Ep,k )−
                             k=i
                              j
                              X
                         −           (σk,p+1 + 1)P (σ − Ek,p + Ek,p+1 )
                             k=p+2



It is next claimed that (4.1.5) is 0 unless i ≤ p < j:


Indeed, if p ≤ i − 1 then both σ − Ep+1,p + Ep,p and σ − Ep+1,p + Ep+1,p+1 are non-effective
                                            Pp−1
(since σp+1,p = 0); moreover, the first sum k=i in (4.1.5) is empty (hence 0), while in the

                                                 50
second sum, each term is 0 (since each σ − Ek,p + Ek,p+1 is non-effective)—hence (4.1.5)
is 0 in this case. Similarly, (4.1.5) is 0 if p ≥ j.
We may thus (without loss of generality) strengthen as follows our earlier assumption:
                    • Throughout the rest of this sub-section, i ≤ p < j.

     For all r between 1 and N , let us set

                 colr (σ) = (r th column-sum of σ) = σ1,r + σ2,r + · · · + σN,r

Because of our hypothesis that
                                        σ ∈ T ERM (τ ) ,

we have                                     (
                                                d,      if r = i;
                               colr (σ) =       Rr (σ), if i < r < j;                     (4.1.6)
                                                0       otherwise.
     Consider next the first expression

                  F = [P (σ − Ep+1,p + Ep,p ) − P (σ − Ep+1,p + Ep+1,p+1 )]               (4.1.7)

occurring on the right side of eq.(4.1.5). Since all diagonal entries of σ vanish (because of
condition I in Def. 3.2.1), it then follows from Prop.2.2.2 that

          P (σ − Ep+1,p + Ep,p ) = P (σ − Ep+1,p )Ep,p − (colp (σ) − 1)P (σ − Ep+1,p )

(if σ − Ep+1,p is effective—but this equation is also valid if σ − Ep+1,p is not effective, since
then both sides are 0)
     Similarly, Prop.2.2.2 implies that

     P (σ − Ep+1,p + Ep+1,p+1 ) = P (σ − Ep+1,p )Ep+1,p+1 − (colp+1 (σ))P (σ − Ep+1,p )

Combining these two equations, with the fact that the left ideal Iλ contains (for all k
between 1 and N )the elements

           Ek,k − Ek+1,k+1 − λ(Ek,k − Ek+1,k+1 ) = Ek,k − Ek+1,k+1 − lk + lk+1

we obtain the following congruence for (4.1.7): modulo Iλ ,

                   F ≡ (lp − lp+1 − colp (σ) + colp+1 (σ) + 1)P (σ − Ep+1,p )

                                                   51
    Inserting this last congruence into (4.1.5),we obtain

           [Ep,p+1 , P (σ)] ≡ (lp − lp+1 − colp (σ) + colp+1 (σ) + 1)P (σ − Ep+1,p )              (4.1.8)
                                      p−1
                                      X
                                  +         (σp,k + 1)(P (σ − Ep+1,k + Ep,k )−
                                      k=i
                                       j
                                       X
                                  −           (σk,p+1 + 1)P (σ − Ek,p + Ek,p+1 )
                                      k=p+2



           Step Two: Expansion of [Ep,p+1 , γ] into Multi-polarizations

    We combine (4.1.8), with
                                                     X
                            [Ep,p+1 , γ] =                    hσ; τ i[Ep,p+1, P (σ)]
                                                 σ∈T ERM (τ )

to obtain the congruence
                                         [Ep,p+1 , γ] ≡ Sp′ + Sp′′ + Sp′′′ ,                      (4.1.9)

where
                       X
        Sp′ =                  hσ; τ i(lp − lp+1 − colp (σ) + colp+1 (σ) + 1)P (σ − Ep+1,p ) (4.1.9a)
                   σ∈T ERM (τ )

                       X          p−1
                                  X
        Sp′′   =                        hσ; τ i(σp,k + 1)P (σ − Ep+1,k + Ep,k )                  (4.1.9b)
                   σ∈T ERM (τ ) k=i
                                                                                                     and
                         X              j
                                        X
        Sp′′′ = −                             hσ; τ i(σk,p+1 + 1)P (σ − Ek,p + Ek,p+1 )          (4.1.9c)
                     σ∈T ERM (τ ) k=p+2


    We must next collect coefficients of the various P’s in (4.1.9):

Lemma 4.1.1.
                                  X
        [Ep,p+1 , γ] ≡                        {Ap (σ) + Bp (σ) + Cp (σ)}P (σ − Ep+1,p )          (4.1.10)
                           σ∈T ERM (τ )

where
                                  X
               Ap (σ) =                       ((lp − lp+1 − colp (σ) + colp+1 (σ) + 1)hσ; τ i   (4.1.10a)
                           σ∈T ERM (τ )


                                                         52
                         p−1
                         X
              Bp (σ) =         σp,k hσ + Ep+1,k − Ep,k − Ep+1,p ; τ i                   (4.1.10b)
                         k=i
                                                                                             and
                               j
                               X
              Cp (σ) = −           σk,p+1 hσ + Ek,p − Ek,p+1 − Ep+1,p ; τ i             (4.1.10c)
                           k=p+2


    Note: As explained earlier, in the present paper we adopt everywhere the two con-
ventions, that
                                   σ 6∈ T ERM (τ ) ⇒ hσ; τ i = 0 .

and that
                         σ ∈ ΠN
                              ± and σ non-effective, imply P (σ) = 0


In particular, the preceding equations are to be interpreted in this way. Thus, in the
ensuing argument, some caution will be needed, to distinguish the ‘regular’ terms in these
sums, from those which are assigned the value 0 by the conventions just reviewed.
    Proof of Lemma 4.1.1: To prove the Lemma, it clearly suffices to verify the following
two assertions:
    CLAIM ONE : If σ ∈ T ERM (τ ) then P (σ − Ep+1,p ) either is 0, or has the same
coefficient on both sides of (4.1.10).
    CLAIM TWO : If P (σ ′ ) occurs with nonzero coefficient as a term in at least one of
the three sums (4.1.10a, b, c), then σ ′ + Ep+1,p ∈ T ERM (τ ).
PROOF OF CLAIM ONE :


Let σ ∈ T ERM (τ ). We distinguish two cases:
Case One: σp+1,p = 0
    Here σ − Ep+1,p is ineffective, so

                                        P (σ − Ep+1,p ) = 0 ,

(and so the value chosen for its coefficient cannot affect the validity of (4.1.10)).
Case Two: σp+1,p ≥ 1
    Here σ − Ep+1,p is effective. Now let us list those terms in the three sums (4.1.9a,b,c)
for which the assigned argument inside the symbol P, is precisely σ − Ep+1,p .
Inside (4.1.9a): There occurs one such term, with coefficient given by (4.1.10a).

                                                 53
Inside (4.1.9b): Precisely one such term (i.e., containing P (σ − Ep+1,p )) is assigned to
each ordered pair (σ ′ , k) with

                                    σ ′ ∈ T ERM (τ ),         i≤k<p

and such that
                                 σ ′ − Ep+1,k − Ep,k = σ − Ep+1,p

—i.e., such that
                                        def
                           σ ′ = σ(k)′ = σ − Ep+1,p + Ep+1,k − Ep,k .                        (4.1.11b)

To be explicit, to each such (σ ′ , k) corresponds the term

                                     def
                           Tb (σ ′ , k) = hσ ′ ; τ i(σp,k
                                                      ′
                                                          + 1)P (σ − Ep+1,p ) .

Thus, if we set
                           F = {k : i ≤ k < p and σ(k)′ ∈ T ERM (τ )

then the sum of the coefficients of P (σ − Ep+1,p ) for all such Tb (σ ′ , k), is
                      X                                          X
                           {(σ(k)′ )p,k + 1}hσ ′ (k); τ i =            σp,k hσ(k)′ ; τ i .
                       F                                           F

But there is no change in the value of this sum if we replace
                                                           p−1
                                               X           X
                                                     by
                                                 F         k=i

since by the conventions explained above, if k is such that

                                           σ(k)′ 6∈ T ERM (τ ) ,

then
                                              hσ(k)′ ; τ i = 0 .

Thus the sum of the coefficients of the terms in question is precisely the sum
                                                  p−1
                                                  X
                                     Bp (σ) =           σp,k hσ(k)′ ; τ i
                                                  k=i

given by eq.(4.1.10b).

                                                     54
Inside (4.1.9c): Essentially the same argument, shows that the terms in (4.1.9c) which
involve P (σ − Ep+1,p ), are precisely those of the form
                                  def
                       Tc (σ ′′ , k) = −hσ ′′ ; τ i(σk,p+1
                                                     ′′
                                                           + 1)P (σ − Ep+1,p ) ,

with
                                        def
                          σ ′′ = σ(k)′′ = σ − Ep+1,p + Ek,p − Ek,p+1 ,             (4.1.11c)

where p + 2 ≤ k ≤ j and
                                        σ(k)′′ ∈ T ERM (τ ) .

As before, these terms have sum Cp (σ) given by (4.1.10c).

       PROOF OF CLAIM TWO :
       This is clear for the terms in (4.1.9a).
       Consider next the terms in (4.1.9b). Let

                           T = hσ ′ ; τ i(σp,k
                                           ′
                                               + 1)P (σ ′ − Ep+1,k + Ep,k )

be a non-zero term in (4.1.9b)—so, in particular, we have:

                      σ ′ ∈ T ERM (τ ), and σ ′ − Ep+1,k + Ep,k is effective.

Set
                                σ = σ ′ − Ep+1,k + Ep,k + Ep+1,p

Clearly σ is effective, with σp+1,p > 0. Since the weight-vector wt(σ) defined by eq.(1.10)
is additive, and since
                                 ǫ(Ep+1,k + Ep,k + Ep+1,p ) = 0 ,

it follows that
                                        ǫ(σ) = ǫ(σ ′ ) = rα .

Hence σ satisfies conditions II) and III) in Def.3.2.1. It is also immediate from k < p that
σ satisfies condition I) in this definition.Hence σ ∈ T ERM (τ ),and so

                     σ ′ = σ(k)′ , and the term T coincides with Tb (σ ′ , k) ,

as was to be proved.
       The case of non-zero terms inside (4.1.9c) is precisely similar.
                        This completes the proof of Lemma 4.1.1.

The following simple lemma embodies an argument used in the preceding, and will find
several further applications below.

                                                  55
Lemma 4.1.2. Assume

                             i ≤ p ≤ j, σ ∈ T ERM (τ ), σp+1,p > 0 .

a)Suppose also i ≤ k < p ; then we have:

                          σ(k)′ ∈ T ERM (τ ) ⇐⇒ σ(k)′ is effective,

where
                                   def
                             σ(k)′ = σ − Ep+1,p + Ep+1,k − Ep,k .

b)Suppose instead p + 2 ≤ k < j; then we have

                          σ(k)′′ ∈ T ERM (τ ) ⇐⇒ σ(k)′′ is effective,

where
                                   def
                             σ(k)′′ = σ − Ep+1,p + Ek,p − Ek,p+1 .

    Proof: If i ≤ k < p then −Ep+1,p + Ep+1,k − Ep,k has excess vector 0; since the excess
vector ǫ is additive,
                                   ǫ(σ(k)′ ) = ǫ(σ) + 0 = dα .

The assertion a) is now clear from the Remark in §3.2. The proof of b) is similar.

                   Step Three            End-game: Proof [Ep,p+1 , γ] = 0

    We are still assuming that i ≤ p ≤ j − 1, and that
                                                        N
                                                        X
                                    τ = (λi − λj , r,         lk λk )
                                                        k=1

is a Verma triple—whence
                                         li − lj − i + j = r .                       (4.1.13)

    Let Gp denote the set of all σ in T ERM (τ ) such that

                        σ − Ep+1,p is effective, i.e. such that σp+1,p ≥ 1           (4.1.14)

By Lemma 4.1.1, the desired result

                                           [Ep,p+1 , γ] = 0

                                                  56
will follow, if we show for every σ in Gp , that the expression (4.1.10) equals 0.
    Thus, to complete the proof of (4.1.3), it suffices to verify, for all σ ∈ Gp , that

                                   Ap (σ) + Bp (σ) + Cp (σ) = 0                          (4.1.15)

where
                  Ap (σ) = {lp − lp+1 − colp (σ) + colp+1 (σ) + 1} · hσ; τ i
                             p−1
                             X
                  Bp (σ) =         σp,k hσ + Ep+1,k − Ep,k − Ep+1,p ; τ i
                             k=i
                        and
                                   j
                                   X
                  Cp (σ) = −           σk,p+1 hσ + Ek,p − Ek,p+1 − Ep+1,p ; τ i
                               k=p+2



    From here on, we shall write Rk for

                                        j
                                        X               j
                                                        X
                             Rk (σ) =          σk,l =         σl,k = colk (σ)
                                         l=i            l=i


(as given by Def.3.1.1 and by eqn. (4.1.6); and will also set

                                           Sk = r − Rk .


    The proof of (4.1.15) divides at this point into three cases, according as

                              p = i, i < p < j − 1 or p = j − 1 .


CASE I:        p=i
    Let σ ∈ Gi . Here (4.1.14) becomes σi+1,i > 0 . Since σ ∈ T ERM (τ ),

                              coli (σ) = r and coli+1 (σ) = Ri+1 ,

so that

            Ai (σ) = (li − li+1 − r + Ri+1 + 1) · hσ; τ i                                (4.1.16)
                                                    j−1
                                                    Y                               
                                                                   li − li+1 − i + q
                   = (li − li+1 − Si+1 + 1) · r! ·       Rq !Sq !
                                                   q=i+1
                                                                           Sq

                                                   57
Bi (σ) = 0 in the present case, since the sum in (4.1.15b) here becomes a sum over the
empty indexing set {k : i ≤ k ≤ i − 1}.

We must next evaluate
                                                        j
                                                        X
                                    Ci (σ) = −                  σk,i+1 hσ(k)′′ ; τ i
                                                      k=i+2

where, for
                                                     i+2 ≤k ≤j                                  (4.1.17) ,

we set, as before,
                              σ(k)′′ = σ + Ek,i − Ek,i+1 − Ei+1,i .

Now,
                                           
                                            σk,i + 1                  if (s, t) = (k, i)
                                           
                                             σk,i+1 − 1                if (s, t) = (k, i + 1)
                      (σ(k)′′ )s,t       =
                                            i+1,i − 1 ≥ 0
                                            σ                         if (s, t) = (i + 1, i)
                                             σs,t                      otherwise
and since σ is effective, it follows that σ(k)′′ is effective, if and only if σk,i+1 > 0. It is now
helpful (still assuming (4.1.17)), to divide into two sub-cases:
Sub-case Ia:         σk,i+1 > 0
     Here, σ(k)′′ is effective, hence, by Lemma 4.1.2, is in T ERM (τ ). Thus, Def.3.2.2 is
applicable, and if we set

                         Rq′′ = Rq (σ(k)′′ ), Sq′′ = r − Rq′′ for i < q < j ,

we have
                                                    j−1
                                                    Y                                      
                             ′′                                             li − lq − i + q
                      hσ(k) ; τ i = r! ·                (Rq′′ )!(Sq′′ )!
                                                   q=i+1
                                                                                   Sq′′

We next compute the integers Rq′′ , Sq′′ in this formula:
     Since σ(k)′′ ∈ T ERM (τ ),

                                             N                       q−1
                                             X                       X
                                  Rq′′   =                ′′
                                                   (σ(k) )q,s =            (σ(k)′′ )q,s
                                             s=1                     s=i


Thus,

         ′′
        Ri+1 = (σ(k)′′ )i+1,i = σi+1,i + 0 − 0 − 1 = Ri − 1, Si+1
                                                              ′′         ′′
                                                                  = d − Ri+1 = Si + 1 ;

                                                               58
while for i + 2 ≤ q ≤ j − 1,

          Rq′′ = (σ(k)′′ )q+1,q + · · · + (σ(k)′′ )j,q = σq+1,q + · · · + σj,q = Rq , Sq′′ = Sq .

Thus                                                                     
                            ′′                              li − li+1 + 1
                      hσ(k) ; τ i = (Ri+1 − 1)!(Si+1 + 1)!                  ·T                      (4.1.18)
                                                               Si+1 + 1
where
                                           j−1
                                           Y                             
                                                          li − lq − i + q
                                 T = r! ·       Rq !Sq !                    .                   (4.1.18a)
                                          q=i+2
                                                                 Sq

This of course trivially implies
                                                                             
                       ′′                                        li − li+1 + 1
         σk,i+1 · hσ(k) ; τ i = σk,i+1 · (Ri+1 − 1)!(Si+1 + 1)!                 ·T                  (4.1.19)
                                                                    Si+1 + 1
(This last deduction may seem less silly in a second.)
       Sub-case Ib:         σk,i+1 = 0 Here (4.1.18) is in general false, but (4.1.19) is still
valid! Namely, here σ(k)′′ is not effective, so by the conventions we are using,

                                              hσ(k)′′ ; τ i = 0 .

Thus, in general Def.3.2.2, i.e., (4.1.18), need not hold in this case— but both sides of
(4.1.19) are here 0.
(Note also that hσ(k)′′ ; τ i is independent of k in sub-case Ia), while it takes the (in general
different) value 0 in sub-case Ib).)

       Thus, we have proved that (4.1.19) holds for all k such that (4.1.17) holds. Together
with
                                                      j
                                                      X
                                           Ri+1 =            σk,i+1
                                                     k=i+2

we obtain
                             j
                             X                                                  
                                                                   li − li+1 + 1
              Ci (σ) = −(       σk,i+1 ) · (Ri+1 − 1)!(Si+1 + 1)!                  ·T
                                                                      Si+1 + 1
                          k=i+2
                                                          
                                             li − li+1 + 1
                     = −Ri+1 !(Si+1 + 1)!                    ·T
                                                Si+1 + 1
Let us rewrite (4.1.16) as
                                                                              
                                                                 li − li+1 + 1
                 Ai (σ) = (li − li+1 − Si+1 + 1) · Ri+1 !Si+1 !                  ·T
                                                                     Si+1

                                                      59
(with T still given by (4.1.18a)) Thus we have

                                  Ai (σ) + Bi (σ) + Ci (σ) =
                                                                                 
                                         li − li+1 + 1                  li − li+1 + 1
    Ri+1 !Si+1 ! (li − li+1 − Si+1 + 1)                  − (Si+1 + 1)!                  T
                                             Si+1                           Si+1

which is seen to vanish upon replacing, in the following elementary combinatorial identity,
M by li − li+1 + 1 and N by Si+1 :
                                                      
                                      M              M
                            (M − N )     = (N + 1)                                   (4.1.20) ,
                                      N             N +1

(valid for M any complex number, N any non-negative integer.)

                           This proves (4.1.15) when p = i.

CASE II:        i<p<j−1
    Let σ ∈ Gp . Thus,
                              σ ∈ T ERM (τ ), and σp+1,p ≥ 1 .

Both p and p + 1 are strictly between i and j. We have

                           colp (σ) = Rp , and colp+1 (σ) = Rp+1 ,

and so
                                                       Y                        
                                                                 li − lq − i + q
     Ap (σ) = (lp − lp+1 − Rp + Rp+1 + 1) · r! ·       Rq !Sq !                       (4.1.21)
                                                 i<q<j
                                                                        Sq


    Consider next
                                            p−1
                                            X
                                 Bp (σ) =         σp,k hσ(k)′ ; τ i
                                            k=i

where (as before)
                           σ(k)′ = σ + Ep+1,k − Ep,k − Ep+1,p .

Its evaluation (which, with a few modifications, is quite similar to the evaluation just
completed of Cp (σ) in Case I) proceeds as follows:
    Since σp+1,p > 0, and k < p, and since σ is effective, we see that

                             σ(k)′ is effective ⇐⇒ σp,k > 0 .

                                              60
Accordingly, we now divide the study of σ(k)′ into two sub-cases, depending on whether
or not σp,k is 0.

    Sub-case IIa:          σp,k > 0 , i ≤ k < p
    In sub-case IIa), σ(k)′ is effective, hence, by Lemma 4.2.2, is in T ERM (τ ). Thus, if
we set
                           Rq′ = Rq (σ(k)′ ), Sq′ = Sq (σ(k)′ ) = r − Rq′

then (in the present sub-case)

                                            j−1
                                            Y                                    
                                ′                                 li − lq − i + q
                        hσ(k) ; τ i =   r!      (Rq′ )!(Sq′ )!
                                           q=i+1
                                                                         Sq′

In this formula, the integers Rq′ , Sq′ associated with σ(k)′ coincide with the same integers
for σ, except possibly for q = p, p + 1 or k; while

         Rp′ = Rp − 1, Rp+1 = Rp+1 , Rt′ = Rt ; so Sp′ = Sp + 1, Sp+1
                                                                  ′
                                                                      = Sp+1 , St′ = St .

Thus, the amplitude is here given by
                                                                      
                           ′                           li − lp − i + p
                     hσ(k) ; τ i = (Rp − 1)!(Sp + 1)!                    · T′           (4.1.22)
                                                           Sp + 1

where                                                                      
                                           Y                li − lq − i + q
                                ′
                               T = r! ·           Rq !Sq !                             (4.1.22a)
                                                                   Sq
                                           q6=p
                                          i<q<j

and so of course
                                                                           
                           ′                                 li − lp − i + p
                 σp,k hσ(k) ; τ i = σp,k (Rp − 1)!(Sp + 1)!                   · T′      (4.1.23)
                                                                 Sp + 1

    Sub-case IIb:          σp,k = 0 , i ≤ k < p

    (4.1.23) remins valid in the present sub-case, since both sides are 0.

    Thus, in Sub-cases IIa) and IIb) alike, (4.1.23) is valid, and since

                                                     p−1
                                                     X
                                             Rp =          σp,k
                                                     k=i

                                                     61
it follows that
                                  p−1
                                  X                                          
                                                               li − lp − i + p ′
                        Bp (σ) =     σp,k (Rp − 1)!(Sp + 1)!                    T                 (4.1.24)
                                                                    Sp + 1
                                 k=i
                                                              
                                                li − lp − i + p ′
                               = Rp !(Sp + 1)!                    T
                                                    Sp + 1


    We next turn to the computation of

                                                   j
                                                   X
                                    Cp (σ) = −           σk,p+1 hσ(k)′′ ; τ i
                                                 k=p+2


where now
                                  σ(k)′′ = σ + Ek,p − Ek,p+1 − Ep+1,p .

This computation is similar to the preceding one of Bp (σ), with the following modifications:
    Assume p + 2 ≤ k ≤ j, σ ∈ Gp .Then

                                  σ(k)′′ is effective ⇐⇒ σk,p+1 > 0 ,

and we have two sub-cases to consider, according as σk,p+1 > 0 or not.
    If σk,p+1 > 0 then (by Lemma 4.1.2) σ(k)′′ is in T ERM (τ ), so we may use Def.3.2.2
to compute the amplitude hσ(k)′′ ; τ i. Since i < s < j, one readily verifies that
                                                                         
              ′′            Rp+1 − 1 if q = p + 1                             Sp+1 + 1 if q = p + 1
     Rq (σ(k) ) =                                  ; Sq (σ(k)′′ ) =
                            Rq       if q 6= p + 1                            Sq       if q 6= p + 1

whence we obtain
                                                                     
                   ′′                           li − lp+1 − i + p + 1
          hσ(k) ; τ i = (Rp+1 − 1)!(Sp+1 + 1)!                          · T ′′                    (4.1.25)
                                                       Sp+1 + 1

where                                                                       
                                           Y                 li − lq − i + q
                                   ′′
                                 T = r!            Rq !Sq !                                      (4.1.25a)
                                                                    Sq
                                          q6=p+1
                                          i<q<j

    Thus, whether σk,p+1 > 0 or not,
                                                                              
                   ′′                                    li − lp+1 − i + p + 1
 σk,p+1 · hσ(k) ; τ i = σk,p+1 · (Rp+1 − 1)!(Sp+1 + 1)!                          · T ′′ (4.1.26)
                                                                Sp+1 + 1

                                                      62
is always valid. Together with
                                                     j
                                                     X
                                        Rp+1 =             σk,p+1 ,
                                                   k=p+2


this yields (as in the preceding discussion of Bp (σ))
                                                                      
                                                 li − lp+1 − i + p + 1
                    Cp (σ) = −Rp+1 !(Sp+1 + 1)!                          · T ′′               (4.1.27)
                                                        Sp+1 + 1

       It is now convenient to introduce the following common divisor of the right-hand sides
of eqns.(4.1.21),(4.1.24) and (4.1.27):
                                                    Y                                   
                                                                         li − lq − i + q
           T = r! · Rp !Sp !(Rp+1 )!(Sp+1 )! ·                 Rq !Sq !                       (4.1.28)
                                                                                Sq
                                                 q6=p,q6=p+1
                                                    i<q<j


Then we have
                                   Ap (σ) + Bp (σ) + Cp (σ) = T U                             (4.1.29)

with
                                                                     
                                                       li − lp − i + p
                    U = (lp − lp+1 − Rp + Rp+1 + 1)                                          (4.1.29a)
                                                              Sp
                                                                     
                                  li − lp − i + p li − lp+1 − i + p + 1
                      + (Sp + 1)
                                       Sp + 1               Sp+1
                                                                        
                                     li − lp − i + p li − lp+1 − i + p + 1
                      − (Sp+1 + 1)
                                            Sp               Sp+1 + 1

Thus, to prove (4.1.15), it suffices in the present case to verify that U = 0.
       For this purpose, first observe

   lp − lp+1 − Rp + Rp+1 + 1 = −(li − lp − i + p − Sp ) + (li − lp+1 − i + p + 1 − Sp+1 )

so that we may write
                                                                   
                          li − lp − i + p       li − lp+1 − i + p + 1
                      U=                  U1 +                         U2
                                 Sp                     Sp+1

with
                                                                                      
                              li − lp+1 − i + p + 1                li − lp+1 − i + p + 1
U1 = (li −lp+1 −i+p+1−Sp+1 )                          −(Sp+1 +1)
                                      Sp+1                                Sp+1 + 1

                                                     63
and
                                                                                 
                                        li − lP − i + p              li − lp − i + p
         U2 = −(li − lp − i + p − Sp )                   + (Sp + 1)
                                               Sp                        Sp + 1

and then observe that U1 and U2 both vanish because of (4.1.20).

                         This proves (4.1.15) when i < p < j − 1.

CASE III:         p=j−1
      Remark: Up to this point, the argument has made no use of the Verma condition.
In other words, except for the single value j − 1 for p, (4.1.3) holds with no restrictions on
the value of λ. Thus, it can be predicted that we shall need to utilize the Verma condition
(4.1), in the present (final remaining) case, i.e. to utilize

                                       li − lj − i + j = r .


      Let us begin by noting that

                     colp (σ) = colj−1 (σ) = Rj−1 , colp+1 (σ) = colj (σ) = 0 ,

so                                                                              
                                                     Y           li − lq − i + q
        Aj−1 (σ) = (lj−1 − lj − Rj−1 + 1) · r! ·       Rq !Sq !                         (4.1.30)
                                                 i<q<j
                                                                        Sq

      Next, we note that in the present case,

                                           Cp (σ) = 0 ,
                Pj
since the sum     k=p+2   on the right side of (4.1.15c), is here extended over the empty set
{k : j + 1 ≤ k ≤ j}.

      Finally, we must evaluate
                                                  j−2
                                                  X
                            Bp (σ) = Bj−1 (σ) =         σj−1,k hσ(k)′ ; τ i
                                                  k=i

with σ(k)′ defined (for the present value of p, and for i ≤ k ≤ j − 2) by

                     σ(k)′ = σ − Ej,j−1 + Ej,k − Ej−1,k (for i ≤ k ≤ j − 2)

                                                64
CLAIM:For i ≤ k ≤ j − 2,
                                                                         
                      ′                             li − lj−1 − i + j − 1
          σj−1,k hσ(k) ; τ i = σj−1,k · (Sj−1 + 1)                          ·T       (4.1.31)
                                                           Sj−1 + 1

where
                                           j−2
                                           Y                            
                                                         li − lq − i + q
                      T = r!Rj−1 !Sj−1 !       Rq !Sq !                             (4.1.31a)
                                         q=i+1
                                                                Sq

    The proof is much the same as that used before, to derive the value obtained for
Ci (σ) in Case I, and used in Case II to derive Bp (σ) (eqn. 4.1.24), and Cp (σ) (eqn.4.1.27).
Namely:
    If σp−1,k = 0, then both sides of (4.1.31) are 0. Otherwise, σ(k)′ is effective, hence
lies in T ERM (τ ) (by a last use of Lemma 4.2.2), so we may use Def.3.2.2 to compute the
amplitude hσ(k)′ ; τ i. Noting for this purpose, that if i < s < j, then we have
                                                              
           ′        Rj−1 − 1 if s = j − 1                 ′      Sj − 1 + 1 if s = j − 1
  Rs (σ(k) ) =                               ;so Ss (σ(k) ) =
                    Rs          if s < j1                        Ss          if s < j − 1

it follows immediately that
                                                                   
                           ′                   li − lj−1 − i + j − 1
                     hσ(k) ; τ i = (Sj−1 + 1)                         ·T
                                                      Sj−1 + 1

                     This completes the proof of Claim (4.1.31).
    Combining (4.1.31) with
                                                 j−2
                                                 X
                                      Rj−1 =           σj−1,k
                                                 k=i

now yields the desired evaluation
                                                                 
                                             li − lj−1 − i + j − 1
                      Bj−1 (σ) = (Sj−1 + 1)                         ·T
                                                    Sj−1 + 1

Let us also rewrite (4.1.30) as
                                                                       
                                                  li − lj−1 − i + j − 1
               Aj−1 (σ) = (lj−1 − lj − Rj−1 + 1)                          ·T
                                                          Sj−1

    Then we get

                             Aj−1 (σ) + Bj−1 (σ) + Cj−1 (σ) =
                                                                                  
                          li − lj−1 − i + j − 1                 li − lj−1 − i + j − 1
  (lj−1 − lj − Rj−1 + 1)                          + (Sj−1 + 1)                           ·T
                                  Sj−1                                Sj−1 + 1)

                                                 65
Thus, in order to prove (4.1.15), in the present case, it is sufficient to verify that the
following expression U vanishes:
                                                                                    
                             li − lj−1 − i + j − 1                li − lj−1 − i + j − 1
 U = (lj−1 − lj − Rj−1 + 1)                         + (Sj−1 + 1)
                                     Sj−1                               Sj−1 + 1)

Using (4.1.20), we obtain
                           
       li − lj−1 − i + j − 1
   U=                         [(lj−1 − lj − Rj−1 + 1) + (li − lj−1 − i + j − 1 − Sj−1 )]
               Sj−1
                           
       li − lj−1 − i + j − 1
    =                         [li − lj − i + j − (Rj−1 + Sj−1 )]
               Sj−1
                           
       li − lj−1 − i + j − 1
    =                         [li − lj − i + j − r]
               Sj−1

which indeed vanishes whenever the Verma condition (4.1)—i.e.


                                    li − lj − i + j = r


—is satisfied.
    We have thus proved eqn.(4.1.15), hence also eqn.(4.1.3), in all three cases.


                  This completes the proof of the assertion A1.


                        §4.2 Proof that γ · vλ has Weight λ − rα

    We next turn to the proof of A2, which asserts that the element γ·vλ in the slN -module
Vλ has weight λ − rα.
    Now, for every N -shift σ, it follows from eqn.(1.11) in §1.3, that P (σ)vλ has weight


                               wt(σ) + wt(vλ ) = wt(σ) + λ ,


where the weight wt(σ) is given by eqn.(1.10). Since γ is, by definition, a Z-linear combi-
nation of
                               {P (σ) : σ ∈ T ERM (i, j, r)}

the desired assertion A2 will be an immediate consequence of the following lemma:

                                            66
Lemma 4.2.1. Let σ ∈ T ERM (i, j, r);then

                                     wt(σ) = −r · (λi − λj )

     PROOF: By hypothesis, σ satisfies the three conditions I),II),III) of Def.3.2.1. It
must then be proved that, for all k between 1 and N inclusive,

                                 wtk (σ) = −r · (λi − λj )(Ek,k )

i.e., that
                            N
                            X               N
                                            X
                                   σk,l −         σl,k = r · (δj,k − δi,k )              (4.2.1)
                             l=1            l=1

There are four cases to check:
CASE 1: k = i
Here the first sum in (4.2.1) vanishes, by condition I) of Def.3.2.1, so we are left with

                                             N
                                             X
                                                   σi,l = r
                                             l=1


which is precisely condition II).
CASE 2: i < k < j
Here the equation to be proved is

                                     N
                                     X               N
                                                     X
                                            σk,l −         σl,k = 0
                                      l=1            l=1


which holds (for all k in the given range) by condition III).
CASE 3: k = j
Here the second sum in (4.2.1) vanishes by Condition I), and we are left to prove:

                                             j−1
                                             X
                                                   σj,l = r                              (4.2.2)
                                             l=i


For i ≤ s < j let us set
                                                                         X
                    C(s) = σs+1,s + σs+2,s + · · · + σj,s +                       σq,p
                                                                      i≤p<s<q≤j


                                                     67
Note that
                                                X
                                     C(i) =            σk,i = r
                                               i<k≤j

by condition I), while for i < s < j,
                                                  X                X
                         C(s) − C(s − 1) =               σs,k −           σs,k
                                                 i≤k<s            s<k≤j


which equals 0 by Condition III) of Def.3.2.1.Hence C(j − 1) = r, which is the same as
(4.2.2).
CASE 4:k < i or k > j
Here both of the sums occurring in (4.2.1) are empty.
     This completes the proof of (4.2.1), and hence of Assertion A2.

    §4.3 Proof that γ satisfies the Shapovalov normalization condition VS2)

     Let us define an N -shift σ to be lower-triangular if it has this property:

                             for all k, l ∈ N , σk,l 6= 0 ⇒ k > l .

Denote by (ΠN )LT the set of all such. (Note that all the P (σ) involved in the formula
(4.1) for γ have lower-triangular σ.)
     Choose (arbitrarily) a total ordering << for ∆+ , say

                                        α1 << · · · << αm

where
                       αs = (i(s), j(s)) with i(s) < j(s) (1 ≤ s ≤ m)

     This in turn induces a total ordering (which by a slight abuse of notation will also be
denoted by << ) on the set of all lower-triangular N -shifts, defined as follows:
     To each lower-triangular N -shift σ assign the ordered m-tuple

                             def
                         hσi = (σj(1),i(1) , σj(2),i(2) , · · · , σj(m),i(m) )

Given a second lower-triangular N -shift τ , we shall say that σ precedes τ in the given total
ordering,
                                             σ << τ ,

                                                  68
if and only if hσi precedes hτ i in the usual lexicographic ordering on ordered m-tuples of
non-negative integers.
    The weight W (σ) of any N -shift σ is defined to be

                                               def
                                                     X
                                       W (σ) =                 σk,l .
                                                     k,l∈N


    As in §3.1, we assign to every lower-triangular N -shift σ, the basis-vector

                  Fσ := (Ej(1),i(1) )σ(j(1),i(1)) · · · · · (Ej(m),i(m) )σ(j(m),i(m))

in the PBW-basis
                                              
                                  B(<<) = {Fσ σ ∈ (ΠN )LT }                            (4.3.1)

for A(N− ) determined by <<.
    We take the usual filtration for the enveloping algebra A(N− ), whereby the s-th
filtration-level A(N− )s is the C-span of all products of ≤ s elements Ei,j with i > j.
Note that then A(N− )s has basis consisting of
                              
                          {Fσ σ is lower-triangular of weight ≤ s}


Lemma 4.3.1. Let σ be a lower-triangular N -shift. Let 1 ≤ k < l ≤ N .Then we may
write
                                                           L
                                                           X
                                El,k Fσ = FEl,k +σ +               cp · Fσp
                                                           p=1

where L is a non-negative integer (which may be zero), each cp is a complex number, and

                                             σ1 , · · · , σL

are lower-triangular N -shifts of weight smaller than that of σ.

PROOF:
Immediate.

Lemma 4.3.2. Let σ be a lower-triangular N -shift. Express the Weyl polarization P (σ)
as a C-linear combination of the basis B(<<) for A(N− ), say:
                                         X            
                               P (σ) =       {Cτ · Fτ τ ∈ (ΠN )LT }                    (4.3.2)

                                                  69
(where all Cτ are complex numbers). Then

                                                      1
                                             Cσ =         ,
                                                     (σ)!

and
                                     Cτ 6= 0 ⇒ W (τ ) < W (σ) .

PROOF:
      We argue by induction on W = W (σ):
      If W=1, then for suitable k, l in N , we have

                                          k < l, σ = El,k .

Hence P (σ) = Dl,k = FEl,k , σ! = 1, and the assertion is clear in this case.
      Next, assume that W > 1, and that the Lemma to be proved holds for all lower-
triangular N -shifts of weight < W .
      It follows immediately from the induction hypothesis, that if τ is a lower-triangular
N -shift of weight W ′ < W , then P (τ ) lies in A(N− )W ′ .
      There exist integers k, l with

                                      1 ≤ k < l ≤ N, σl,k > 0 .

By Cor.2.3.2, there then exist lower-triangular N-shifts

                                             σ1 , · · · , σL

(with L ≥ 0), each of weight W − 1, and positive integers m1 , · · · , mL , such that

                                                               L
                                                               X
                        σl,k · P (σ) = El,k P (σ − Ei,j ) −          ms P (σs ) .       (4.3.3)
                                                               s=1

By the induction hypothesis applied to the N -shift σ − El,k of weight W − 1, we may write

                                   1
             P (σ − El,k ) =                Fσ−El,k + ( an element in A(N− )W −2 ) .
                               (σ − El,k )!

Hence, using Lemma 4.3.1, it follows that

                                         1
              El,k P (σ − El,k ) =                Fσ + ( an element in A(N− )W −1 ) .
                                     (σ − El,k )!

                                                  70
Since
                                                           1
                                     (σ − El,k )! =            · (σ)! ,
                                                          σl,k
we may rewrite (4.3.3) as
                                    1
                          P (σ) =      Fσ + ( an element in A(N− )W −1 )
                                    σ!
which completes the induction, and so the proof of Lemma 4.3.2.

       Our present purpose is the proof of assertion A3, i.e., the proof that γ satisfies the
Shapovalov normalization property VS2) explained in §3.1. Let σ0 denote the N -shift

                                 σ0 = r(Ei+1,i + · · · + Ej−1,j ) .                        (4.3.4)

The assertion to be proved is, that when γ is expressed as a C-linear combination of the
basis (4.3.1) for A(N− ), the coefficient of the basis vector Fσ0 is precisely 1.
       To see this, let us recall eqn.(4.1), which defined γ as:

                                         def
                                                X
                                      γ =             hσ; τ iP (σ)                         (4.3.5)
                                               σ∈T (τ )

where
                                      T (τ ) = T ERM (i, j, r) ,

is the set of lower-triangular N -shifts subordinate to (λi − λj , r), as furnished by Def.3.1.1.
In particular, the three conditions of Def.3.1.1 are satisfied by the N -shift (4.3.4), i.e. T (τ )
contains σ0 .
       CLAIM: σ0 has strictly larger weight than any other member of T (τ ).
       PROOF:If σ1 is any element of T (τ ), and σ1 is distinct from σ0 , then we may write

                                           σ1 = El,k + σ1′

with
                          i ≤ k < l ≤ j, l − k > 1, and σ1′ effective.

Then the N-shift
                                       El,k+1 + Ek+1,k + σ1′

lies in T (τ ), and has weight larger by 1 than that of σ1 —which completes the proof of the
Claim.

                                                    71
    Combining the result just proved with Lemma 4.3.2 and eqn.(4.3.5), we obtain:

                             hσ0 ; τ i
                        γ=             Fσ0 + ( an element in A(N− )r(i−j)−1 )
                               σ0 !
i.e., there exist distinct lower-triangular

                                              σ1 , σ2 , · · · , σL ,

all of weight strictly less than that of σ0 , and complex numbers Cs , such that

                                                      X         L
                                      hσ0 ; τ i
                                   γ=           Fσ0 +     Cs Fσs                       (4.3.6)
                                        σ0 !          s=1

Let us now appeal to Def.3.2.2 in order to compute hσ0 ; τ i. Here we must replace each
Kσ (k) in eqn.(3.2.2) by r, thus obtaining
                                               j−1
                                               Y                    
                                                             li − lk
                         hσ0 ; τ i = (r!) ·           [r!0!           ] = (r!)j−i
                                                                0
                                              k=i+1

But clearly eqn.(4.3.4) implies that

                                              (σ0 )! = (r!)j−1

Hence, we see that the coefficient of Fσ0 in the right-hand side of eqn.(4.3.6) is 1, as was
to be proved.
    This completes the proof of Assertion A3, hence of Theorem 3.3.4, and so also of all
the assertions in §3.
                                                 References

     [Akin1] K.AKIN, On Complexes Relating the Jacobi-Trudi Identity with the
                Bernstein-Gelfand-Gelfand Resolution I. J. of Alg. 117 (1988), 494–503
     [Akin2] K.AKIN, On Complexes Relating the Jacobi-Trudi Identity with the
                Bernstein-Gelfand-Gelfand Resolution II. J. of Alg. 152 (1992), 417–
                426
      [BGG] I.N.BERNSTEIN, I.M.GEL’FAND and S.I.GEL’FAND, Differential op-
                erators on the base affine space and a study of g-modules, in ‘Lie Groups
                and their Representations’, Proc. of the summer school on group repre-
                sentations, Bolyai Jańos Math. Society, Budapest, (1971) , Wiley (New
                York–Toronto 1975) 21–64

                                                       72
 [Cap1] A.CAPELLI, Über die Zurückfürung der Cayley’schen Operation Ω auf
         gewöhnliche Polar-Operationen, Math.Ann. 29(1887), 331–338
 [Cap2] A.CAPELLI, Sur les opérations dans la théorie des formes algébriques,
         Math.Ann.37(1890),1–37
 [Cap3] A.CAPELLI, Lezioni sulla Theoria delle Forme Algebriche,
         Pellerano,Napoli,1902
   [CL] R.W.CARTER AND G.LUSZTIG, On the modular representations of
         the general linear and symmetric groups. Math.Z.136(1974)193–242
  [Doty] S.R.DOTY, The Symmetric Algebra and Representations of General
         Linear Groups, Proceedings of the Hyderabad Conference on Algebraic
         Groups, (Dec.1989), 123–150
 [Doty2] S.R.DOTY, Resolutions of B Modules, Indag.Mathem.,N.S., 5(3),267–
         283 (Sept. 26, 1994)
   [Fra] J.FRANKLIN, Homomorphisms between Verma Modules in Character-
         istic p. J. of Alg. 112(1988)58–85
   [FH] W.FULTON and J.HARRIS, Representation Theory, A First Course,
         129, Graduate Texts in Mathematics, Springer Verlag, 1991
[Greene] GREENE
   [Las] A.LASCOUX, Syzygies des variétés déterminentales, Advances in Math.
         301, (1978), 202–237
   [Mal] M.MALIAKAS,Resolutions and parabolic Schur algebras. J. Alg. 180,
         (1996),679—690
[Mathas] A.MATHAS, Iwahori-Hecke Algebras and Schur Algebras of the Sym-
         metric Group, AMS University Lecure Series 15(1991)
  [MFF] F.G.MALIKOV;B.L.FEIGIN;D.FUKS. Singular vectors in Verma mod-
         ules over Kac - Moody algebras. (Russian) Funkts. Anal. i Prilozhen.
         20 (1986), no. 2, 25–37, 96.
[Nielsen] A.NIELSEN, Tensor Functors of Complexes, Aarhus Universitet, Mate-
         matiske Institut, Preprint Series 77/78, No.15
  [Shap] N.N.SHAPOVALOV, On a bilinear form on the universal enveloping
         algebra of a complex semisimple Lie algebra, Functional Anal. Appl. .6,
         (1972), 307–312
[Umeda] T.UMEDA, The Capelli Identities, A Century After, Amer. Math. Soc.

                                        73
         Transl. 2 Vol.183, 1998
[Verma1] D.-N. VERMA, Structure of Certain Induced Representations of Com-
         plex Semisimple Lie Algebras, Yale University Doctoral Dissertation,
         (1966)
[Verma2] D.-N. VERMA, Structure of certain induced representations of complex
         semisimple Lie algebras, Bull.A.M.S. 74(1968), 160–166
  [Weyl] H.WEYL, The Classical Groups, Their Invariants and Representations,
         Princeton University Press, 1946
 [Wood] D.J.WOODCOCK, Comm. Alg. 22, no.5,(1994),1703–1721
 [Young] A.YOUNG, On Quantitative Substitutional Analysis I, PLMS 33 (1900)
         97–146
    [Zel] A.ZELEVINSKY, Resolvents, Dual pairs, and Character Formulas,
         Functional Anal. Appl. , 21 (1987), 152–154




                                      74
